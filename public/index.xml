<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CLRS on Solutions</title>
    <link>http://walkccc.github.io/CLRS/</link>
    <description>Recent content in CLRS on Solutions</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    
	<atom:link href="http://walkccc.github.io/CLRS/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>15-1 Longest simple path in a directed acyclic graph</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-1/</guid>
      <description>Suppose that we are given a directed acyclic graph $G = (V, E)$ with real-valued edge weights and two distinguished vertices $s$ and $t$ . Describe a dynamic-programming approach for finding a longest weighted simple path from $s$ to $t$ . What does the subproblem graph look like? What is the efficiency of your algorithm?
 We will make use of the optimal substructure property of longest paths in acyclic graphs.</description>
    </item>
    
    <item>
      <title>15-2 Longest palindrome subsequence</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-2/</guid>
      <description>A palindrome is a nonempty string over some alphabet that reads the same forward and backward. Examples of palindromes are all strings of length $1$, $\text{civic}$, $\text{racecar}$, and $\text{aibohphobia}$ (fear of palindromes).
Give an efficient algorithm to find the longest palindrome that is a subsequence of a given input string. For example, given the input $\text{character}$, your algorithm should return $\text{carac}$. What is the running time of your algorithm?</description>
    </item>
    
    <item>
      <title>15-3 Bitonic euclidean</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-3/</guid>
      <description>In the euclidean traveling-salesman problem, we are given a set of $n$ points in the plane, and we wish to find the shortest closed tour that connects all n points. Figure 15.11(a) shows the solution to a 7-point problem. The general problem is NP-hard, and its solution is therefore believed to require more than polynomial time (see Chapter 34).
J. L. Bentley has suggested that we simplify the problem by restricting our attention to bitonic tours, that is, tours that start at the leftmost point, go strictly rightward to the rightmost point, and then go strictly leftward back to the starting point.</description>
    </item>
    
    <item>
      <title>15-4 Printing neatly</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-4/</guid>
      <description>Consider the problem of neatly printing a paragraph with a monospaced font (all characters having the same width) on a printer. The input text is a sequence of $n$ words of lengths $l_1, l_2, \ldots, l_n$, measured in characters. We want to print this paragraph neatly on a number of lines that hold a maximum of $M$ characters each. Our criterion of &amp;ldquo;neatness&amp;rdquo; is as follows. If a given line contains words $i$ through $j$, where $i \le j$ , and we leave exactly one space between words, the number of extra space characters at the end of the line is $M - j + i - \sum_{k = i}^j l_k$, which must be nonnegative so that the words fit on the line.</description>
    </item>
    
    <item>
      <title>15-5 Edit distance</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-5/</guid>
      <description>In order to transform one source string of text $x[1..m]$ to a target string $y[1..n]$, we can perform various transformation operations. Our goal is, given $x$ and $y$, to produce a series of transformations that change $x$ to $y$. We use an array $z$—assumed to be large enough to hold all the characters it will need—to hold the intermediate results. Initially, $z$ is empty, and at termination, we should have $z[j] = y[j]$ for $j = 1, 2, \ldots, n$.</description>
    </item>
    
    <item>
      <title>15-6 Planning a company party</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-6/</guid>
      <description>Professor Stewart is consulting for the president of a corporation that is planning a company party. The company has a hierarchical structure; that is, the supervisor relation forms a tree rooted at the president. The personnel office has ranked each employee with a conviviality rating, which is a real number. In order to make the party fun for all attendees, the president does not want both an employee and his or her immediate supervisor to attend.</description>
    </item>
    
    <item>
      <title>15-7 Viterbi algorithm</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-7/</guid>
      <description>We can use dynamic programming on a directed graph $G = (V, E)$ for speech recognition. Each edge $(u, v) \in E$ is labeled with a sound $\sigma(u, v)$ from a finite set $\Sigma$ of sounds. The labeled graph is a formal model of a person speaking a restricted language. Each path in the graph starting from a distinguished vertex $v_0 \in V$ corresponds to a possible sequence of sounds producted by the model.</description>
    </item>
    
    <item>
      <title>15-8 Image compression by seam carving</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-8/</guid>
      <description>We are given a color picture consisting of an $m \times n$ array $A[1..m, 1..n]$ of pixels, where each pixel specifies a triple of red, green, and blue (RGB) intensities. Suppose that we wish to compress this picture slightly. Specifically, we wish to remove one pixel from each of the $m$ rows, so that the whole picture becomes one pixel narrower. To avoid disturbing visual effects, however, we require that the pixels removed in two adjacent rows be in the same or adjacent columns; the pixels removed form a &amp;ldquo;seam&amp;rdquo; from the top row to the bottom row where successive pixels in the seam are adjacent vertically or diagonally.</description>
    </item>
    
    <item>
      <title>15-9 Breaking a string</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-9/</guid>
      <description>A certain string-processing language allows a programmer to break a string into two pieces. Because this operation copies the string, it costs $n$ time units to break a string of $n$ characters into two pieces. Suppose a programmer wants to break a string into many pieces. The order in which the breaks occur can affect the total amount of time used. For example, suppose that the programmer wants to break a $20$-character string after characters $2$, $8$, and $10$ (numbering the characters in ascending order from the left-hand end, starting from $1$).</description>
    </item>
    
    <item>
      <title>15-10 Planning an investment strategy</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-10/</guid>
      <description>Your knowledge of algorithms helps you obtain an exciting job with the Acme Computer Company, along with a $\$10,000$ signing bonus. You decide to invest this money with the goal of maximizing your return at the end of 10 years. You decide to use the Amalgamated Investment Company to manage your investments. Amalgamated Investments requires you to observe the following rules. It offers $n$ different investments, numbered $1$ through $n$.</description>
    </item>
    
    <item>
      <title>15-11 Inventory planning</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-11/</guid>
      <description>The Rinky Dink Company makes machines that resurface ice rinks. The demand for such products varies from month to month, and so the company needs to develop a strategy to plan its manufacturing given the fluctuating, but predictable, demand. The company wishes to design a plan for the next $n$ months. For each month $i$, the company knows the demand $d_i$, that is, the number of machines that it will sell.</description>
    </item>
    
    <item>
      <title>15-12 Signing free-agent baseball players</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/problems/15-12/</guid>
      <description>Suppose that you are the general manager for a major-league baseball team. During the off-season, you need to sign some free-agent players for your team. The team owner has given you a budget of $\$X$ to spend on free agents. You are allowed to spend less than $\$X$ altogether, but the owner will fire you if you spend any more than $\$X$.
You are considering $N$ different positions, and for each position, $P$ free-agent players who play that position are available.</description>
    </item>
    
    <item>
      <title>1-1 Comparison of running times</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap01/problems/1-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap01/problems/1-1/</guid>
      <description>For each function $f(n)$ and time $t$ in the following table, determine the largest size $n$ of a problem that can be solved in time $t$, assuming that the algorithm to solve the problem takes $f(n)$ microseconds.
  $$ \begin{array}{cccccccc} &amp; \text{1 second} &amp; \text{1 minute} &amp; \text{1 hour} &amp; \text{1 day} &amp; \text{1 month} &amp; \text{1 year} &amp; \text{1 century} \\ \lg n &amp; 2^{10^6} &amp; 2^{6 \times 10^6} &amp; 2^{3.</description>
    </item>
    
    <item>
      <title>1.1 Algorithms</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap01/1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap01/1.1/</guid>
      <description>1.1-1  Give a real-world example that requires sorting or a real-world example that requires computing a convex hull.
  Sorting: browse the price of the restaurants with ascending prices on NTU street. Convex hull: computing the diameter of set of points.  1.1-2  Other than speed, what other measures of efficiency might one use in a real-world setting?
 Memory efficiency and coding efficiency.
1.1-3  Select a data structure that you have seen previously, and discuss its strengths and limitations.</description>
    </item>
    
    <item>
      <title>1.2 Algorithm as a technology</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap01/1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap01/1.2/</guid>
      <description>1.2-1  Give an example of an application that requires algorithmic content at the application level, and discuss the function of the algorithms involved.
 Drive navigation.
1.2-2  Suppose we are comparing implementations of insertion sort and merge sort on the same machine. For inputs of size $n$ , insertion sort runs in $8n^2$ steps, while merge sort runs in $64n\lg n$ steps. For which values of $n$ does insertion sort beat merge sort?</description>
    </item>
    
    <item>
      <title>10-1 Comparisons among lists</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-1/</guid>
      <description> For each of the four types of lists in the following table, what is the asymptotic worst-case running time for each dynamic-set operation listed?
 $$ \begin{array}{l|cccc} &amp; \text{unsorted, singly linked} &amp; \text{sorted, singly linked} &amp; \text{unsorted, doubly linked} &amp; \text{sorted, doubly linked} \\ \text{SEARCH($L, k$)} &amp; &amp; &amp; &amp; \\ \text{INSERT($L, x$)} &amp; &amp; &amp; &amp; \\ \text{DELETE($L, x$)} &amp; &amp; &amp; &amp; \\ \text{SUCCESSOR($L, x$)} &amp; &amp; &amp; &amp; \\ \text{PREDECESSOR($L, x$)} &amp; &amp; &amp; &amp; \\ \text{MINIMUM($L$)} &amp; &amp; &amp; &amp; \\ \text{MAXIMUM($L$)} &amp; &amp; &amp; &amp; \end{array} $$    $$ \begin{array}{l|cccc} &amp; \text{unsorted, singly linked} &amp; \text{sorted, singly linked} &amp; \text{unsorted, doubly linked} &amp; \text{sorted, doubly linked} \\ \text{SEARCH($L, k$)} &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(n) \\ \text{INSERT($L, x$)} &amp; \Theta(1) &amp; \Theta(n) &amp; \Theta(1) &amp; \Theta(n) \\ \text{DELETE($L, x$)} &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(1) &amp; \Theta(1) \\ \text{SUCCESSOR($L, x$)} &amp; \Theta(n) &amp; \Theta(1) &amp; \Theta(n) &amp; \Theta(1) \\ \text{PREDECESSOR($L, x$)} &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(1) \\ \text{MINIMUM($L$)} &amp; \Theta(n) &amp; \Theta(1) &amp; \Theta(n) &amp; \Theta(1) \\ \text{MAXIMUM($L$)} &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(n) &amp; \Theta(n) \end{array} $$  </description>
    </item>
    
    <item>
      <title>10-2 Mergeable heaps using linked lists</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-2/</guid>
      <description>A mergeable heap supports the following operations: $\text{MAKE-HEAP}$ (which creates an empty mergeable heap), $\text{INSERT}$, $\text{MINIMUM}$, $\text{EXTRACT-MIN}$, and $\text{UNION}$. Show how to implement mergeable heaps using linked lists in each of the following cases. Try to make each operation as efficient as possible. Analyze the running time of each operation in terms of the size of the dynamic set(s) being operated on.
a. Lists are sorted.
b. Lists are unsorted.</description>
    </item>
    
    <item>
      <title>10-3 Searching a sorted compact list</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/problems/10-3/</guid>
      <description>Exercise 10.3-4 asked how we might maintain an n-element list compactly in the first n positions of an array. We shall assume that all keys are distinct and that the compact list is also sorted, that is, $key[i] &amp;lt; key[next[i]]$ for all $i = 1, 2, \ldots, n$ such that $next[i] \ne \text{NIL}$. We will also assume that we have a variable $L$ that contains the index of the first element on the list.</description>
    </item>
    
    <item>
      <title>10.1 Stacks and queues</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.1/</guid>
      <description>10.1-1  Using Figure 10.1 as a model, illustrate the result of each operation in the sequence $\text{PUSH}(S, 4)$, $\text{PUSH}(S, 1)$, $\text{PUSH}(S, 3)$, $\text{POP}(S)$, $\text{PUSH}(S, 8)$, and $\text{POP}(S)$ on an initially empty stack $S$ stored in array $S[1..6]$.
  $$ \begin{array}{l|ccc} \text{PUSH($S, 4$)} &amp; 4 &amp; &amp; \\ \text{PUSH($S, 1$)} &amp; 4 &amp; 1 &amp; \\ \text{PUSH($S, 3$)} &amp; 4 &amp; 1 &amp; 3 \\ \text{POP($S$)} &amp; 4 &amp; 1 &amp; \\ \text{PUSH($S, 8$)} &amp; 4 &amp; 1 &amp; 8 \\ \text{POP($S$)} &amp; 4 &amp; 1 &amp; \end{array} $$  10.</description>
    </item>
    
    <item>
      <title>10.2 Linked lists</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.2/</guid>
      <description>10.2-1  Can you implement the dynamic-set operation $\text{INSERT}$ on a singly linked list in $O(1)$ time? How about $\text{DELETE}$?
  $\text{INSERT}$: can be implemented in constant time by prepending it to the list.
LIST-INSERT(L, x) x.next = L.head L.head = x  $\text{DELETE}$: cannot be implemented in constant time, unless you pass to it as an argument the predecessor of the element you are deleting.
  10.</description>
    </item>
    
    <item>
      <title>10.3 Implementing pointers and objects</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.3/</guid>
      <description>10.3-1  Draw a picture of the sequence $\langle 13, 4, 8, 19, 5, 11 \rangle$ stored as a doubly linked list using the multiple-array representation. Do the same for the single-array representation.
  A multiple array version could be $L = 2$,
 $$ \begin{array}{ccccccc} / &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; / \\ &amp; 12 &amp; 4 &amp; 8 &amp; 19 &amp; 5 &amp; 11 \\ &amp; &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 \end{array} $$  A single array version could be $L = 4$,</description>
    </item>
    
    <item>
      <title>10.4 Representing rooted trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap10/10.4/</guid>
      <description>10.4-1  Draw the binary tree rooted at index 6 that is represented by the following attributes:
 $$ \begin{array}{cccc} \text{index} &amp; key &amp; left &amp; right \\ 1 &amp; 12 &amp; 7 &amp; 3 \\ 2 &amp; 15 &amp; 8 &amp; \text{NIL} \\ 3 &amp; 4 &amp; 10 &amp; \text{NIL} \\ 4 &amp; 10 &amp; 5 &amp; 9 \\ 5 &amp; 2 &amp; \text{NIL} &amp; \text{NIL} \\ 6 &amp; 18 &amp; 1 &amp; 4 \\ 7 &amp; 7 &amp; \text{NIL} &amp; \text{NIL} \\ 8 &amp; 14 &amp; 6 &amp; 2 \\ 9 &amp; 21 &amp; \text{NIL} &amp; \text{NIL} \\ 10 &amp; 5 &amp; \text{NIL} &amp; \text{NIL} \end{array} $$   10.</description>
    </item>
    
    <item>
      <title>11-1 Longest-probe bound for hashing</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-1/</guid>
      <description>Suppose that we use an open-addressed hash table of size $m$ to store $n \le m / 2$ items.
a. Assuming uniform hashing, show that for $i = 1, 2, \ldots, n$, the probability is at most $2^{-k}$ that the $i$th insertion requires strictly more than $k$ probes.
b. Show that for $i = 1, 2, \ldots, n$, the probability is $O(1 / n^2)$ that the $i$th insertion requires more than $2\lg n$ probes.</description>
    </item>
    
    <item>
      <title>11-2 Slot-size bound for chaining</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-2/</guid>
      <description>Suppose that we have a hash table with $n$ slots, with collisions resolved by chaining, and suppose that $n$ keys are inserted into the table. Each key is equally likely to be hashed to each slot. Let $M$ be the maximum number of keys in any slot after all the keys have been inserted. Your mission is to prove an $O(\lg n / \lg\lg n)$ upper bound on $\text E[M]$, the expected value of $M$.</description>
    </item>
    
    <item>
      <title>11-3 Quadratic probing</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-3/</guid>
      <description>Suppose that we are given a key $k$ to search for in a hash table with positions $0, 1, \ldots, m - 1$, and suppose that we have a hash function $h$ mapping the key space into the set ${0, 1, \ldots, m - 1}$. The search scheme is as follows:
 Compute the value $j = h(k)$, and set $i = 0$. Probe in position $j$ for the desired key $k$.</description>
    </item>
    
    <item>
      <title>11-4 Hashing and authentication</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/problems/11-4/</guid>
      <description>Let $\mathcal H$ be a class of hash functions in which each hash function $h \in \mathcal H$ maps the universe $U$ of keys to ${0, 1, \ldots, m - 1}$. We say that $\mathcal H$ is k-universal if, for every fixed sequence of $k$ distinct keys $\langle x^{(1)}, x^{(2)}, \ldots, x^{(k)} \rangle$ and for any $h$ chosen at random from $\mathcal H$, the sequence $\langle h(x^{(1)}), h(x^{(2)}), \ldots, h(x^{(k)}) \rangle$ is equally likely to be any of the $m^k$ sequences of length $k$ with elements drawn from ${0, 1, \ldots, m - 1}$.</description>
    </item>
    
    <item>
      <title>11.1 Direct-address tables</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.1/</guid>
      <description>11.1-1  Suppose that a dynamic set $S$ is represented by a direct-address table $T$ of length $m$. Describe a procedure that finds the maximum element of $S$. What is the worst-case performance of your procedure?
 As the dynamic set $S$ is represented by the direct-address table $T$, for each key $k$ in $S$, there is a slot $k$ in $T$ points to it. If no element with key $k$ in $S$, then $T[k] = \text{NIL}$.</description>
    </item>
    
    <item>
      <title>11.2 Hash tables</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.2/</guid>
      <description>11.2-1  Suppose we use a hash function $h$ to hash $n$ distinct keys into an array $T$ of length $m$. Assuming simple uniform hashing, what is the expected number of collisions? More precisely, what is the expected cardinality of $\{\{k, l\}: k \ne l \text{ and } h(k) = h(l)\}$?
 For each pair of keys $k$, $l$, where $k \ne l$, define the indicator random variable $X_{kl} = \text I\{h(k) = h(l)\}$.</description>
    </item>
    
    <item>
      <title>11.3 Hash functions</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.3/</guid>
      <description>11.3-1  Suppose we wish to search a linked list of length $n$, where each element contains a key $k$ along with a hash value $h(k)$. Each key is a long character string. How might we take advantage of the hash values when searching the list for an element with a given key?
 If every element also contained a hash of the long character string, when we are searching for the desired element, we&amp;rsquo;ll first check if the hashvalue of the node in the linked list, and move on if it disagrees.</description>
    </item>
    
    <item>
      <title>11.4 Open addressing</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.4/</guid>
      <description>11.4-1  Consider inserting the keys $10, 22, 31, 4, 15, 28, 17, 88, 59$ into a hash table of length $m = 11$ using open addressing with the auxiliary hash function $h^\prime(k) = k$. Illustrate the result of inserting these keys using linear probing, using quadratic probing with $c_1 = 1$ and $c_2 = 3$, and using double hashing with $h_1(k) = k$ and $h_2(k) = 1 + (k \mod (m - 1))$.</description>
    </item>
    
    <item>
      <title>11.5 Perfect hashing</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap11/11.5/</guid>
      <description>11.5-1 $\star$  Suppose that we insert $n$ keys into a hash table of size $m$ using open addressing and uniform hashing. Let $p(n, m)$ be the probability that no collisions occur. Show that $p(n, m) \le e^{-n(n - 1) / 2m}$. ($\textit{Hint:}$ See equation $\text{(3.12)}$.) Argue that when $n$ exceeds $m$, the probability of avoiding collisions goes rapidly to zero.
  $$ \begin{aligned} p(n, m) &amp; = \frac{m}{m} \cdot \frac{m - 1}{m} \cdots \frac{m - n + 1}{m} \\ &amp; = \frac{m \cdot (m - 1) \cdots (m - n + 1)}{m^n} \end{aligned} $$   $$ \begin{aligned} (m - i) \cdot (m - n + i) &amp; = (m - \frac{n}{2} + \frac{n}{2} - i) \cdot (m - \frac{n}{2} - \frac{n}{2} + i) \\ &amp; = (m - \frac{n}{2})^2 - (i - \frac{n}{2})^2 \\ &amp; \le (m - \frac{n}{2})^2 \end{aligned} $$   $$ \begin{aligned} p(n, m) &amp; \le \frac{m \cdot (m - \frac{n}{2})^{n - 1}}{m^n} \\ &amp; = (1 - \frac{n}{2m}) ^ {n - 1}.</description>
    </item>
    
    <item>
      <title>12-1 Binary search trees with equal keys</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-1/</guid>
      <description>Equal keys pose a problem for the implementation of binary search trees.
a. What is the asymptotic performance of $\text{TREE-INSERT}$ when used to insert $n$ items with identical keys into an initially empty binary search tree?
We propose to improve $\text{TREE-INSERT}$ by testing before line 5 to determine whether $z.key = x.key$ and by testing before line 11 to determine whether $z.key = y.key$.
If equality holds, we implement one of the following strategies.</description>
    </item>
    
    <item>
      <title>12-2 Radix trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-2/</guid>
      <description>Given two strings $a = a_0a_1 \ldots a_p$ and $b = b_0b_1 \ldots b_q$, where each $a_i$ and each $b_j$ is in some ordered set of characters, we say that string $a$ is lexicographically less than string $b$ if either
 there exists an integer $j$, where $0 \le j \le \min(p, q)$, such that $a_i = b_i$ for all $i = 0, 1, \ldots j - 1$ and $a_j &amp;lt; b_j$, or $p &amp;lt; q$ and $a_i = b_i$ for all $i = 0, 1, \ldots, p$.</description>
    </item>
    
    <item>
      <title>12-3 Average node depth in a randomly built binary search tree</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-3/</guid>
      <description>In this problem, we prove that the average depth of a node in a randomly built binary search tree with n nodes is $O(\lg n)$. Although this result is weaker than that of Theorem 12.4, the technique we shall use reveals a surprising similarity between the building of a binary search tree and the execution of $\text{RANDOMIZED-QUICKSORT}$ from Section 7.3.
We define the total path length $P(T)$ of a binary tree $T$ as the sum, over all nodes $x$ in $T$, of the depth of node $x$, which we denote by $d(x, T)$.</description>
    </item>
    
    <item>
      <title>12-4 Number of different binary trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/problems/12-4/</guid>
      <description>Let $b_n$ denote the number of different binary trees with $n$ nodes. In this problem, you will find a formula for $b_n$, as well as an asymptotic estimate.
a. Show that $b_0 = 1$ and that, for $n \ge 1$,
 $$ b_n = \sum_{k = 0}^{n - 1} b_k b_{n - 1 - k}. $$  b. Referring to Problem 4-4 for the definition of a generating function, let $B(x)$ be the generating function</description>
    </item>
    
    <item>
      <title>12.1 What is a binary search tree?</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.1/</guid>
      <description>12.1-1  For the set of $\langle 1, 4, 5, 10, 16, 17, 21 \rangle$ of keys, draw binary search trees of heights $2$, $3$, $4$, $5$, and $6$.
  $height = 2$:
 $height = 3$:
 $height = 4$:
 $height = 5$:
 $height = 6$:
  12.1-2  What is the difference between the binary-search-tree property and the min-heap property (see page 153)? Can the min-heap property be used to print out the keys of an $n$-node tree in sorted order in $O(n)$ time?</description>
    </item>
    
    <item>
      <title>12.2 Querying a binary search tree</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.2/</guid>
      <description>12.2-1  Suppose that we have numbers between $1$ and $1000$ in a binary search tree, and we want to search for the number $363$. Which of the following sequences could not be the sequence of nodes examined?
a. $2, 252, 401, 398, 330, 344, 397, 363$.
b. $924, 220, 911, 244, 898, 258, 362, 363$.
c. $925, 202, 911, 240, 912, 245, 363$.
d. $2, 399, 387, 219, 266, 382, 381, 278, 363$.</description>
    </item>
    
    <item>
      <title>12.3 Insertion and deletion</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.3/</guid>
      <description>12.3-1  Give a recursive version of the $\text{TREE-INSERT}$ procedure.
 INSERT(value) root = INSERT(value, root)  TREE-INSERT(value, node) if node == NIL initialize BSTnode(value) else if node.key &amp;gt; value node.left = INSERT(value, node.left) else node.right = INSERT(value, node.right) return node  12.3-2  Suppose that we construct a binary search tree by repeatedly inserting distinct values into the tree. Argue that the number of nodes examined in searching for a value in the tree is one plus the number of nodes examined when the value was first inserted into the tree.</description>
    </item>
    
    <item>
      <title>12.4 Randomly built binary search trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap12/12.4/</guid>
      <description>12.4-1  Prove equation $\text{(12.3)}$.
 $$ \sum_{i = 0}^{n - 1} \binom{i + 3}{3} = \binom{n + 3}{4}. \tag{12.3} $$   $$ \begin{aligned} \sum_{i = 0}^{n - 1} \binom{i + 3}{3} &amp; = \sum_{i = 0}^{n - 1} \frac{(i + 3)(i + 2)(i + 1)}{6} \\ &amp; = \frac{1}{6} \sum_{i = 0}^{n - 1} i^3 + 6i^2 + 11i + 6 \\ &amp; = \frac{1}{6} (\frac{(n - 1)^2 n^2}{4} + \frac{6(n - 1)n(2n - 1)}{6} + \frac{11n(n - 1)}{2} + 6n) \\ &amp; = \frac{n(n + 1)(n + 2)(n + 3)}{24} \\ &amp; = \binom{n + 3}{4}.</description>
    </item>
    
    <item>
      <title>13-1 Persistent dynamic sets</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-1/</guid>
      <description>During the course of an algorithm, we sometimes find that we need to maintain past versions of a dynamic set as it is updated. We call such a set persistent. One way to implement a persistent set is to copy the entire set whenever it is modified, but this approach can slow down a program and also consume much space. Sometimes, we can do much better.
Consider a persistent set $S$ with the operations $\text{INSERT}$, $\text{DELETE}$, and $\text{SEARCH}$, which we implement using binary search trees as shown in Figure 13.</description>
    </item>
    
    <item>
      <title>13-2 Join operation on red-black trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-2/</guid>
      <description>The join operation takes two dynamic sets $S_1$ and $S_2$ and an element $x$ such that for any $x_1 \in S_1$ and $x_2 \in S_2$, we have $x_1.key \le x.key \le x_2.key$. It returns a set $S = S_1 \cup {x} \cup S_2$. In this problem, we investigate how to implement the join operation on red-black trees.
a. Given a red-black tree $T$, let us store its black-height as the new attribute $T.</description>
    </item>
    
    <item>
      <title>13-3 AVL trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-3/</guid>
      <description>An AVL tree is a binary search tree that is height balanced: for each node $x$, the heights of the left and right subtrees of $x$ differ by at most $1$. To implement an AVL tree, we maintain an extra attribute in each node: $x.h$ is the height of node $x$. As for any other binary search tree $T$, we assume that $T.root$ points to the root node.
a. Prove that an AVL tree with $n$ nodes has height $O(\lg n)$.</description>
    </item>
    
    <item>
      <title>13-4 Treaps</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/problems/13-4/</guid>
      <description>If we insert a set of $n$ items into a binary search tree, the resulting tree may be horribly unbalanced, leading to long search times. As we saw in Section 12.4, however, randomly built binary search trees tend to be balanced. Therefore, one strategy that, on average, builds a balanced tree for a fixed set of items would be to randomly permute the items and then insert them in that order into the tree.</description>
    </item>
    
    <item>
      <title>13.1 Properties of red-black trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.1/</guid>
      <description>13.1-1  In the style of Figure 13.1(a), draw the complete binary search tree of height $3$ on the keys $\{1, 2, \ldots, 15\}$. Add the $\text{NIL}$ leaves and color the nodes in three different ways such that the black-heights of the resulting red-black trees are $2$, $3$, and $4$.
  Complete binary tree of $height = 3$:
 Red-black tree of $black\text-heights = 2$:
 Red-black tree of $black\text-heights = 3$:</description>
    </item>
    
    <item>
      <title>13.2 Rotations</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.2/</guid>
      <description>13.2-1  Write pseudocode for $\text{RIGHT-ROTATE}$.
 RIGHT-ROTATE(T, y) x = y-&amp;gt;left y-&amp;gt;left = x-&amp;gt;right if x-&amp;gt;right != T.nil x-&amp;gt;right.p = y x.p = y.p if y.p == T.nil T.root = x else if y == y.p-&amp;gt;right y.p-&amp;gt;right = x else y.p-&amp;gt;left = x x-&amp;gt;right = y y.p = x  13.2-2  Argue that in every $n$-node binary search tree, there are exactly $n - 1$ possible rotations.</description>
    </item>
    
    <item>
      <title>13.3 Insertion</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.3/</guid>
      <description>13.3-1  In line 16 of $\text{RB-INSERT}$, we set the color of the newly inserted node $z$ to red. Observe that if we had chosen to set $z$&amp;rsquo;s color to black, then property 4 of a red-black tree would not be violated. Why didn&amp;rsquo;t we choose to set $z$&amp;rsquo;s color to black?
 If we chose to set the color of $z$ to black then we would be violating property 5 of being a red-black tree.</description>
    </item>
    
    <item>
      <title>13.4 Deletion</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap13/13.4/</guid>
      <description>13.4-1  Argue that after executing $\text{RB-DELETE-FIXUP}$, the root of the tree must be black.
  Case 1: transform to 2, 3, 4. Case 2: if terminates, the root of the subtree (the new $x$) is set to black. Case 3: transform to 4. Case 4: the root (the new $x$) is set to black.  13.4-2  Argue that if in $\text{RB-DELETE}$ both $x$ and $x.p$ are red, then property 4 is restored by the call to $\text{RB-DELETE-FIXUP}(T, x)$.</description>
    </item>
    
    <item>
      <title>14-1 Point of maximum overlap</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap14/problems/14-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap14/problems/14-1/</guid>
      <description>Suppose that we wish to keep track of a point of maximum overlap in a set of intervals—a point with the largest number of intervals in the set that overlap it.
a. Show that there will always be a point of maximum overlap that is an endpoint of one of the segments.
b. Design a data structure that efficiently supports the operations $\text{INTERVAL-INSERT}$, $\text{INTERVAL-DELETE}$, and $\text{FIND-POM}$, which returns a point of maximum overlap.</description>
    </item>
    
    <item>
      <title>14-2 Josephus permutation</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap14/problems/14-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap14/problems/14-2/</guid>
      <description>We define the Josephus problem as follows. Suppose that $n$ people form a circle and that we are given a positive integer $m \ge n$. Beginning with a designated first person, we proceed around the circle, removing every $m$th person. After each person is removed, counting continues around the circle that remains. This process continues until we have removed all $n$ people. The order in which the people are removed from the circle defines the $(n, m)$-Josephus permutation of the integers $1, 2, \ldots, n$.</description>
    </item>
    
    <item>
      <title>14.1 Dynamic order statistics</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.1/</guid>
      <description>14.1-1  Show how $\text{OS-SELECT}(T.root, 10)$ operates on the red-black tree $T$ of Figure 14.1.
  $26: r = 13, i = 10$, go left. $17: r = 8, i = 10$, go right. $21: r = 3, i = 2$, go left. $19: r = 1, i = 2$, go right. $20: r = 1, i = 1$, choose $20$.  14.1-2  Show how $\text{OS-RANK}(T, x)$ operates on the red-black tree $T$ of Figure 14.</description>
    </item>
    
    <item>
      <title>14.2 How to augment a data structure</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.2/</guid>
      <description>14.2-1  Show, by adding pointers to the nodes, how to support each of the dynamic-set queries $\text{MINIMUM}$, $\text{MAXIMUM}$, $\text{SUCCESSOR}$, and $\text{PREDECESSOR}$ in $O(1)$worstcase time on an augmented order-statistic tree. The asymptotic performance of other operations on order-statistic trees should not be affected.
  MINIMUM: A pointer points to the minimum node, if the node is being deleted, move the pointer to its successor. MAXIMUM: Similar to $\text{MINIMUM}$. SUCCESSOR: Every node records its successor, the insertion and deletion is similar to that in linked list.</description>
    </item>
    
    <item>
      <title>14.3 Interval trees</title>
      <link>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iii-data-structures/chap14/14.3/</guid>
      <description>14.3-1  Write pseudocode for $\text{LEFT-ROTATE}$ that operates on nodes in an interval tree and updates the $max$ attributes in $O(1)$ time.
 Add 2 lines in $\text{LEFT-ROTATE}$ in 13.2
max[y] = max[x] max[x] = max(high[x], max(left[x]), max(right[x]))  14.3-2  Rewrite the code for $\text{INTERVAL-SEARCH}$ so that it works properly when all intervals are open.
 INTERVAL-SEARCH(T, i) x = T.root while x != T.nil and (i.high ≤ x.</description>
    </item>
    
    <item>
      <title>15.1 Rod cutting</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.1/</guid>
      <description>15.1-1  Show that equation $\text{(15.4)}$ follows from equation $\text{(15.3)}$ and the initial condition $T(0) = 1$.
 We can verify that $T(n) = 2^n$ is a solution to the given recurrence by the substitution method. We note that for $n = 0$, the formula is true since $2^0 = 1$. For $n &amp;gt; 0$, substituting into the recurrence and using the formula for summing a geometric series yields</description>
    </item>
    
    <item>
      <title>15.2 Matrix-chain multiplication</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.2/</guid>
      <description>15.2-1  Find an optimal parenthesization of a matrix-chain product whose sequence of dimensions is $\langle 5, 10, 3, 12, 5, 50, 6 \rangle$.
  $$ ((5 \times 10)(10 \times 3))(((3 \times 12)(12 \times 5))((5 \times 50)(50 \times 6))). $$  15.2-2  Give a recursive algorithm $\text{MATRIX-CHAIN-MULTIPLY}(A, s, i, j)$ that actually performs the optimal matrix-chain multiplication, given the sequence of matrices $\langle A_1, A_2, \ldots ,A_{n_i} \rangle$, the $s$ table computed by $\text{MATRIX-CHAIN-ORDER}$, and the indices $i$ and $j$.</description>
    </item>
    
    <item>
      <title>15.3 Elements of dynamic programming</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.3/</guid>
      <description>15.3-1  Which is a more efficient way to determine the optimal number of multiplications in a matrix-chain multiplication problem: enumerating all the ways of parenthesizing the product and computing the number of multiplications for each, or running $\text{RECURSIVE-MATRIX-CHAIN}$? Justify your answer.
 Running $\text{RECURSIVE-MATRIX-CHAIN}$ is asymptotically more efficient than enumerating all the ways of parenthesizing the product and computing the number of multiplications for each.
Consider the treatment of subproblems by the two approaches.</description>
    </item>
    
    <item>
      <title>15.4 Longest common subsequence</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.4/</guid>
      <description>15.4-1  Determine an $\text{LCS}$ of $\langle 1, 0, 0, 1, 0, 1, 0, 1 \rangle$ and $\langle 0, 1, 0, 1, 1, 0, 1, 1, 0 \rangle$.
 $\langle 1, 0, 0, 1, 1, 0 \rangle$.
15.4-2  Give pseudocode to reconstruct an $\text{LCS}$ from the completed $c$ table and the original sequences $X = \langle x_1, x_2, \ldots, x_m \rangle$ and $Y = \langle y_1, y_2, \ldots, y_n \rangle$ in $O(m + n)$ time, without using the $b$ table.</description>
    </item>
    
    <item>
      <title>15.5 Optimal binary search trees</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap15/15.5/</guid>
      <description>15.5-1  Write pseudocode for the procedure $\text{CONSTRUCT-OPTIMAL-BST}(root)$ which, given the table root, outputs the structure of an optimal binary search tree. For the example in Figure 15.10, your procedure should print out the structure
 $$ \begin{aligned} &amp; \text{$k_4$ is the root} \\ &amp; \text{$k_2$ is the left child of $k_4$} \\ &amp; \text{$k_1$ is the left child of $k_2$} \\ &amp; \text{$d_0$ is the right child of $k_1$} \\ &amp; \text{$d_1$ is the right child of $k_1$} \\ &amp; \text{$k_3$ is the right child of $k_2$} \\ &amp; \text{$d_2$ is the left child of $k_3$} \\ &amp; \text{$d_3$ is the right child of $k_3$} \\ &amp; \text{$k_5$ is the right child of $k_4$} \\ &amp; \text{$d_4$ is the left child of $k_5$} \\ &amp; \text{$d_5$ is the right child of $k_5$} \end{aligned} $$  corresponding to the optimal binary search tree shown in Figure 15.</description>
    </item>
    
    <item>
      <title>16-1 Coin changing</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-1/</guid>
      <description>Consider the problem of making change for $n$ cents using the fewest number of coins. Assume that each coin&amp;rsquo;s value is an integer.
a. Describe a greedy algorithm to make change consisting of quarters, dimes, nickels, and pennies. Prove that your algorithm yields an optimal solution.
b. Suppose that the available coins are in the denominations that are powers of $c$, i.e., the denominations are $c^0, c^1, \ldots, c^k$ for some integers $c &amp;gt; 1$ and $k \ge 1$.</description>
    </item>
    
    <item>
      <title>16-2 Scheduling to minimize average completion time</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-2/</guid>
      <description>Suppose you are given a set $S = \{a_1, a_2, \ldots, a_n\}$ of tasks, where task $a_i$ requires $p_i$ units of processing time to complete, once it has started. You have one computer on which to run these tasks, and the computer can run only one task at a time. Let $c_i$ be the completion time of task $a_i$ , that is, the time at which task $a_i$ completes processing.</description>
    </item>
    
    <item>
      <title>16-3 Acyclic subgraphs</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-3/</guid>
      <description>a. The incidence matrix for an undirected graph $G = (V, E)$ is a $|V| \times |E|$ matrix $M$ such that $M_{ve} = 1$ if edge $e$ is incident on vertex $v$, and $M_{ve} = 0$ otherwise. Argue that a set of columns of $M$ is linearly independent over the field of integers modulo 2 if and only if the corresponding set of edges is acyclic. Then, use the result of Exercise 16.</description>
    </item>
    
    <item>
      <title>16-4 Scheduling variations</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-4/</guid>
      <description>Consider the following algorithm for the problem from Section 16.5 of scheduling unit-time tasks with deadlines and penalties. Let all $n$ time slots be initially empty, where time slot $i$ is the unit-length slot of time that finishes at time $i$. We consider the tasks in order of monotonically decreasing penalty. When considering task $a_j$, if there exists a time slot at or before $a_j$&amp;rsquo;s deadline $d_j$ that is still empty, assign $a_j$ to the latest such slot, filling it.</description>
    </item>
    
    <item>
      <title>16-5 Off-line caching</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/problems/16-5/</guid>
      <description>Modern computers use a cache to store a small amount of data in a fast memory. Even though a program may access large amounts of data, by storing a small subset of the main memory in the cache—a small but faster memory—overall access time can greatly decrease. When a computer program executes, it makes a sequence $\langle r_1, r_2, \ldots, r_n \rangle$ of $n$ memory requests, where each request is for a particular data element.</description>
    </item>
    
    <item>
      <title>16.1 An activity-selection problem</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.1/</guid>
      <description>16.1-1  Give a dynamic-programming algorithm for the activity-selection problem, based on recurrence $\text{(16.2)}$. Have your algorithm compute the sizes $c[i, j]$ as defined above and also produce the maximum-size subset of mutually compatible activities.
Assume that the inputs have been sorted as in equation $\text{(16.1)}$. Compare the running time of your solution to the running time of $\text{GREEDY-ACTIVITY-SELECTOR}$.
 The tricky part is determining which activities are in the set $S_{ij}$.</description>
    </item>
    
    <item>
      <title>16.2 Elements of the greedy strategy</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.2/</guid>
      <description>16.2-1  Prove that the fractional knapsack problem has the greedy-choice property.
 Let $I$ be the following instance of the knapsack problem: Let $n$ be the number of items, let $v_i$ be the value of the $i$th item, let $w_i$ be the weight of the $i$th item and let $W$ be the capacity. Assume the items have been ordered in increasing order by $v_i / w_i$ and that $W \ge w_n$.</description>
    </item>
    
    <item>
      <title>16.3 Huffman codes</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.3/</guid>
      <description>16.3-1  Explain why, in the proof of Lemma 16.2, if $x.freq = b.freq$, then we must have $a.freq = b.freq = x.freq = y.freq$.
 We are given that $x.freq \le y.freq$ are the two lowest frequencies in order, and that $a.freq \le b.freq$. Now,
 $$\begin{array}{rcl} b.freq &amp; = &amp; x.freq \\ \Rightarrow a.freq &amp; \le &amp; x.freq \\ \Rightarrow a.freq &amp; = &amp; x.freq &amp; \text{(since $x.</description>
    </item>
    
    <item>
      <title>16.4 Matroids and greedy methods</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.4/</guid>
      <description>16.4-1  Show that $(S, I_k)$ is a matroid, where $S$ is any finite set and $I_k$ is the set of all subsets of $S$ of size at most $k$, where $k \le |S|$.
 The first condition that $S$ is a finite set is a given. To prove the second condition we assume that $k \ge 0$, this gets us that $\mathcal I_k$ is nonempty. Also, to prove the hereditary property, suppose $A \in \mathcal I_k$ this means that $|A| \le k$.</description>
    </item>
    
    <item>
      <title>16.5 A task-scheduling problem as a matroid</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap16/16.5/</guid>
      <description>16.5-1  Solve the instance of the scheduling problem given in Figure 16.7, but with each penalty $w_i$ replaced by $80 - wi$.
  $$ \begin{array}{c|ccccccc} a_i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 \\ d_i &amp; 4 &amp; 2 &amp; 4 &amp; 3 &amp; 1 &amp; 4 &amp; 6 \\ w_i &amp; 10 &amp; 20 &amp; 30 &amp; 40 &amp; 50 &amp; 60 &amp; 70 \end{array} $$  We begin by just greedily constructing the matroid, adding the most costly to leave incomplete tasks first.</description>
    </item>
    
    <item>
      <title>17-1 Bit-reversed binary counter</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-1/</guid>
      <description>Chapter 30 examines an important algorithm called the fast Fourier transform, or $\text{FFT}$. The first step of the $\text{FFT}$ algorithm performs a bit-reversal permutation on an input array $A[0..n - 1]$ whose length is $n = 2^k$ for some nonnegative integer $k$. This permutation swaps elements whose indices have binary representations that are the reverse of each other.
We can express each index $a$ as a $k$-bit sequence $\langle a_{k - 1}, a_{k - 2}, \ldots, a_0 \rangle$, where $a = \sum_{i = 0}^{k - 1} a_i 2^i$.</description>
    </item>
    
    <item>
      <title>17-2 Making binary search dynamic</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-2/</guid>
      <description>Binary search of a sorted array takes logarithmic search time, but the time to insert a new element is linear in the size of the array. We can improve the time for insertion by keeping several sorted arrays.
Specifically, suppose that we wish to support $\text{SEARCH}$ and $\text{INSERT}$ on a set of $n$ elements. Let $k = \lceil \lg(n + 1) \rceil$, and let the binary representation of $n$ be $\langle n_{k - 1}, n_{k - 2}, \ldots, n_0 \rangle$.</description>
    </item>
    
    <item>
      <title>17-3 Amortized weight-balanced trees</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-3/</guid>
      <description>Consider an ordinary binary search tree augmented by adding to each node $x$ the attribute $x.size$ giving the number of keys stored in the subtree rooted at $x$. Let $\alpha$ be a constant in the range $1 / 2 \le \alpha &amp;lt; 1$. We say that a given node $x$ is $\alpha$-balanced if $x.left.size \le \alpha \cdot x.size$ and $x.right.size \le \alpha \cdot x.size$. The tree as a whole is $\alpha$-balanced if every node in the tree is $\alpha$-balanced.</description>
    </item>
    
    <item>
      <title>17-4 The cost of restructuring red-black trees</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-4/</guid>
      <description>There are four basic operations on red-black trees that perform structural modifications: node insertions, node deletions, rotations, and color changes. We have seen that $\text{RB-INSERT}$ and $\text{RB-DELETE}$ use only $O(1)$ rotations, node insertions, and node deletions to maintain the red-black properties, but they may make many more color changes.
a. Describe a legal red-black tree with $n$ nodes such that calling $\text{RB-INSERT}$ to add the $(n + 1)$st node causes $\Omega(\lg n)$ color changes.</description>
    </item>
    
    <item>
      <title>17-5 Competitive analysis of self-organizing lists with move-to-front</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/problems/17-5/</guid>
      <description>A self-organizing list is a linked list of $n$ elements, in which each element has a unique key. When we search for an element in the list, we are given a key, and we want to find an element with that key.
A self-organizing list has two important properties:
 To find an element in the list, given its key, we must traverse the list from the beginning until we encounter the element with the given key.</description>
    </item>
    
    <item>
      <title>17.1 Aggregate analysis</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.1/</guid>
      <description>17.1-1  If the set of stack operations included a $\text{MULTIPUSH}$ operation, which pushses $k$ items onto the stack, would the $O(1)$ bound on the amortized cost of stack operations continue to hold?
 No. The time complexity of such a series of operations depends on the number of pushes (pops vise versa) could be made. Since one $\text{MULTIPUSH}$ needs $\Theta(k)$ time, performing n $\text{MULTIPUSH}$ operations, each with $k$ elements, would take $\Theta(kn)$ time, leading to amortized cost of $\Theta(k)$.</description>
    </item>
    
    <item>
      <title>17.2 The accounting method</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.2/</guid>
      <description>17.2-1  Suppose we perform a sequence of stack operations on a stack whose size never exceeds $k$. After every $k$ operations, we make a copy of the entire stack for backup purposes. Show that the cost of $n$ stack operations, including copying the stack, is $O(n)$ by assigning suitable amortized costs to the various stack operations.
 [We assume that the only way in which COPY is invoked is automatically, after every sequence of $k$ PUSH and POP operations.</description>
    </item>
    
    <item>
      <title>17.3 The potential method</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.3/</guid>
      <description>17.3-1  Suppose we have a potential function $\Phi$ such that $\Phi(D_i) \ge \Phi(D_0)$ for all $i$, but $\Phi(D_0) \ne 0$. Show that there exists a potential fuction $\Phi^\prime$ such that $\Phi^\prime(D_0) = 0$, $\Phi^\prime(D_i) \ge 0$ for all $i \ge 1$, and the amortized costs using $\Phi^\prime$ are the same as the amortized costs using $\Phi$.
 Define the potential function $\Phi^\prime(D_i) = \Phi(D_i) - \Phi(D_0)$ for all $i \ge 1$.</description>
    </item>
    
    <item>
      <title>17.4 Dynamic tables</title>
      <link>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/iv-advanced-design-and-analysis-techniques/chap17/17.4/</guid>
      <description>17.4-1  Suppose that we wish to implement a dynamic, open-address hash table. Why might we consider the table to be full when its load factor reaches some value $\alpha$ that is strictly less than $1$? Describe briefly how to make insertion into a dynamic, open-address hash table run in such a way that the expected value of the amortized cost per insertion is $O(1)$. Why is the expected value of the actual cost per insertion not necessarily $O(1)$ for all insertions?</description>
    </item>
    
    <item>
      <title>18-1 Stacks on secondary storage</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/problems/18-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/problems/18-1/</guid>
      <description>Consider implementing a stack in a computer that has a relatively small amount of fast primary memory and a relatively large amount of slower disk storage. The operations $\text{PUSH}$ and $\text{POP}$ work on single-word values. The stack we wish to support can grow to be much larger than can fit in memory, and thus most of it must be stored on disk.
A simple, but inefficient, stack implementation keeps the entire stack on disk.</description>
    </item>
    
    <item>
      <title>18-2 Joining and splitting 2-3-4 trees</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/problems/18-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/problems/18-2/</guid>
      <description>The join operation takes two dynamic sets $S^\prime$ and $S^{\prime\prime}$ and an element $x$ such that for any $x^\prime \in S^\prime$ and $x^{\prime\prime} \in S^{\prime\prime}$, we have $x^\prime.key &amp;lt; x.key &amp;lt; x^{\prime\prime}.key$. It returns a set $S = S^\prime \cup \{x\} \cup S^{\prime\prime}$. The split operation is like an &amp;ldquo;inverse&amp;rdquo; join: given a dynamic set $S$ and an element $x \in S$, it creates a set $S^\prime$ that consists of all elements in set $S$ and an element $x \in S$, it creates a set $S^\prime$ that consists of all elements in $S - \{x\}$ whose keys are less than $x.</description>
    </item>
    
    <item>
      <title>18.1 Definition of B-trees</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.1/</guid>
      <description>18.1-1  Why don&amp;rsquo;t we allow a minimum degree of $t = 1$?
 According to the definition, minimum degree $t$ means every node other than the root must have at least $t - 1$ keys, and every internal node other than the root thus has at least $t$ children. So, when $t = 1$, it means every node other than the root must have at least $t - 1 = 0$ key, and every internal node other than the root thus has at least $t = 1$ child.</description>
    </item>
    
    <item>
      <title>18.2 Basic operations on B-trees</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.2/</guid>
      <description>18.2-1  Show the results of inserting the keys
 $$ F, S, Q, K, C, L, H, T, V, W, M, R, N, P, A, B, X, Y, D, Z, E $$  in order into an empty B-tree with minimum degree $2$. Draw only the configurations of the tree just before some node must split, and also draw the final configuration.
 (Omit!)
18.2-2  Explain under what circumstances, if any, redundant $\text{DISK-READ}$ or $\text{DISK-WRITE}$ operations occur during the course of executing a call to $\text{B-TREE-INSERT}$.</description>
    </item>
    
    <item>
      <title>18.3 Deleting a key from a B-tree</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap18/18.3/</guid>
      <description>18.3-1  Show the results of deleting $C$, $P$, and $V$, in order, from the tree of Figure 18.8(f).
  Figure 18.8(f)
 delete $C$
 delete $P$
 delete $V$
  18.3-2  Write pseudocode for $\text{B-TREE-DELETE}$.
 The algorithm $\text{B-TREE-DELETE}(x, k)$ is a recursive procedure which deletes key $k$ from the B-tree rooted at node $x$.
The functions $\text{PREDECESSOR}(k, x)$ and $\text{SUCCESSOR}(k, x)$ return the predecessor and successor of $k$ in the B-tree rooted at $x$ respectively.</description>
    </item>
    
    <item>
      <title>19-1 Alternative implementation of deletion</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-1/</guid>
      <description>Professor Pisano has proposed the following variant of the $\text{FIB-HEAP-DELETE}$ procedure, claiming that it runs faster when the node being deleted is not the node pointed to by $H.min$.
PISANO-DELETE(H, x) if x == H.min FIB-HEAP-EXTRACT-MIN(H) else y = x.p if y != NIL CUT(H, x, y) CASCADING-CUT(H, y) add x&#39;s child list to the root list of H remove x from the root list of H  a. The professor&amp;rsquo;s claim that this procedure runs faster is based partly on the assumption that line 7 can be performed in $O(1)$ actual time.</description>
    </item>
    
    <item>
      <title>19-2 Binomial trees and binomial heaps</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-2/</guid>
      <description>The binomial tree $B_k$ is an ordered tree (see Section B.5.2) defined recursively. As shown in Figure 19.6(a), the binomial tree $B_0$ consists of a single node. The binomial tree $B_k$ consists of two binomial trees $B_{k - 1}$ that are linked together so that the root of one is the leftmost child of the root of the other. Figure 19.6(b) shows the binomial trees $B_0$ through $B_4$.
a. Show that for the binomial tree $B_k$,</description>
    </item>
    
    <item>
      <title>19-3 More Fibonacci-heap operations</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-3/</guid>
      <description>We wish to augment a Fibonacci heap $H$ to support two new operations without changing the amortized running time of any other Fibonacci-heap operations.
a. The operation $\text{FIB-HEAP-CHANGE-KEY}(H, x, k)$ changes the key of node $x$ to the value $k$. Give an efficient implementation of $\text{FIB-HEAP-CHANGE-KEY}$, and analyze the amortized running time of your implementation for the cases in which $k$ is greater than, less than, or equal to $x.</description>
    </item>
    
    <item>
      <title>19-4 2-3-4 heaps</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/problems/19-4/</guid>
      <description>Chapter 18 introduced the 2-3-4 tree, in which every internal node (other than possibly the root) has two, three, or four children and all leaves have the same depth. In this problem, we shall implement 2-3-4 heaps, which support the mergeable-heap operations.
The 2-3-4 heaps differ from 2-3-4 trees in the following ways. In 2-3-4 heaps, only leaves store keys, and each leaf $x$ stores exactly one key in the attribute $x.</description>
    </item>
    
    <item>
      <title>19.1 Structure of Fibonacci heaps</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.1/</guid>
      <description>There is no exercise in this section.</description>
    </item>
    
    <item>
      <title>19.2 Mergeable-heap operations</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.2/</guid>
      <description>19.2-1  Show the Fibonacci heap that results from calling $\text{FIB-HEAP-EXTRACT-MIN}$ on the Fibonacci heap shown in Figure 19.4(m).
 (Omit!)</description>
    </item>
    
    <item>
      <title>19.3 Decreasing a key and deleting a node</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.3/</guid>
      <description>19.3-1  Suppose that a root $x$ in a Fibonacci heap is marked. Explain how $x$ came to be a marked root. Argue that it doesn&amp;rsquo;t matter to the analysis that $x$ is marked, even though it is not a root that was first linked to another node and then lost one child.
 A root in the heap became marked because it at some point had a child whose key was decreased.</description>
    </item>
    
    <item>
      <title>19.4 Bounding the maximum degree</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap19/19.4/</guid>
      <description>19.4-1  Professor Pinocchio claims that the height of an $n$-node Fibonacci heap is $O(\lg n)$. Show that the professor is mistaken by exhibiting, for any positive integer $n$, a sequence of Fibonacci-heap operations that creates a Fibonacci heap consisting of just one tree that is a linear chain of $n$ nodes.
  Initialize: insert 3 numbers then extract-min. Iteration: insert 3 numbers, in which at least two numbers are less than the root of chain, then extract-min.</description>
    </item>
    
    <item>
      <title>2-1 Insertion sort on small arrays in merge sort</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-1/</guid>
      <description>Although merge sort runs in $\Theta(\lg n)$ worst-case time and insertion sort runs in $\Theta(n^2)$ worst-case time, the constant factors in insertion sort can make it faster in practice for small problem sizes on many machines. Thus, it makes sense to coarsen the leaves of the recursion by using insertion sort within merge sort when subproblems become sufficiently small. Consider a modification to merge sort in which $n / k$ sublists of length $k$ are sorted using insertion sort and then merged using the standard merging mechanism, where $k$ is a value to be determined.</description>
    </item>
    
    <item>
      <title>2-2 Correctness of bubblesort</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-2/</guid>
      <description>Bubblesort is a popular, but inefficient, sorting algorithm. It works by repeatedly swapping adjacent elements that are out of order.
BUBBLESORT(A) for i = 1 to A.length - 1 for j = A.length downto i + 1 if A[j] &amp;lt; A[j - 1] exchange A[j] with A[j - 1]  a. Let $A^\prime$ denote the output of $\text{BUBBLESORT}(A)$ To prove that $\text{BUBBLESORT}$ is correct, we need to prove that it terminates and that</description>
    </item>
    
    <item>
      <title>2-3 Correctness of Horner&#39;s rule</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-3/</guid>
      <description>The following code fragment implements Horner&amp;rsquo;s rule for evaluating a polynomial
 $$ \begin{aligned} P(x) &amp; = \sum_{k = 0}^n a_k x^k \\ &amp; = a_0 + x(a_1 + x (a_2 + \cdots + x(a_{n - 1} + x a_n) \cdots)), \end{aligned} $$  given the coefficients $a_0, a_1, \ldots, a_n$ and a value of $x$:
y = 0 for i = n down 0 y = ai + x * y  a.</description>
    </item>
    
    <item>
      <title>2-4 Inversions</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/problems/2-4/</guid>
      <description>Let $A[1..n]$ be an array of $n$ distinct numbers. If $i &amp;lt; j$ and $A[i] &amp;gt; A[j]$, then the pair $(i, j)$ is called an inversion of $A$.
a. List the five inversions in the array $\langle 2, 3, 8, 6, 1 \rangle$.
b. What array with elements from the set ${1, 2, \ldots, n}$ has the most inversions? How many does it have?
c. What is the relationship between the running time of insertion sort and the number of inversions in the input array?</description>
    </item>
    
    <item>
      <title>2.1 Insertion sort</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/2.1/</guid>
      <description>2.1-1  Using Figure 2.2 as a model, illustrate the operation of $\text{INSERTION-SORT}$ on the array $A = \langle 31, 41, 59, 26, 41, 58 \rangle$.
  $$ \begin{aligned} A &amp; = \langle 31, 41, 59, 26, 41, 58 \rangle \\ A &amp; = \langle 31, 41, 59, 26, 41, 58 \rangle \\ A &amp; = \langle 31, 41, 59, 26, 41, 58 \rangle \\ A &amp; = \langle 26, 31, 41, 59, 41, 58 \rangle \\ A &amp; = \langle 26, 31, 41, 41, 59, 58 \rangle \\ A &amp; = \langle 26, 31, 41, 41, 58, 59 \rangle \end{aligned} $$  2.</description>
    </item>
    
    <item>
      <title>2.2 Analyzing algorithms</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/2.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/2.2/</guid>
      <description>2.2-1  Express the function $n^3 / 1000 - 100n^2 - 100n + 3n$ in terms of $\Theta$-notation.
 $\Theta(n^3)$.
2.2-2  Consider sorting $n$ numbers stored in array $A$ by first finding the smallest element of $A$ and exchanging it with the element in $A[1]$. Then find the second smallest element of $A$, and exchange it with $A[2]$. Continue in this manner for the first $n - 1$ elements of $A$.</description>
    </item>
    
    <item>
      <title>2.3 Designing algorithms</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap02/2.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap02/2.3/</guid>
      <description>2.3-1  Using Figure 2.4 as a model, illustrate the operation of merge sort on the array $A = \langle 3, 41, 52, 26, 38, 57, 9, 49 \rangle$.
  $$ [3] \quad [41] \quad [52] \quad [26] \quad [38] \quad [57] \quad [9] \quad [49] $$ $$ \downarrow $$ $$ [3|41] \quad [26| 52] \quad [38|57] \quad [9|49] $$ $$ \downarrow $$ $$ [3|26|41|52] \quad [9 |38|49|57] $$ $$ \downarrow $$ $$ [3|9|26|38|41|49|52|57] $$  2.</description>
    </item>
    
    <item>
      <title>20-1 Space requirements for van Emde Boas trees</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/problems/20-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/problems/20-1/</guid>
      <description>This problem explores the space requirements for van Emde Boas trees and suggests a way to modify the data structure to make its space requirement depend on the number $n$ of elements actually stored in the tree, rather than on the universe size $u$. For simplicity, assume that $\sqrt u$ is always an integer.
a. Explain why the following recurrence characterizes the space requirement $P(u)$ of a van Emde Boas tree with universe size u:</description>
    </item>
    
    <item>
      <title>20-2 $y$-fast tries</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/problems/20-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/problems/20-2/</guid>
      <description>This problem investigates D. Willard&amp;rsquo;s &amp;ldquo;$y$-fast tries&amp;rdquo; which, like van Emde Boas trees, perform each of the operations $\text{MEMBER}$, $\text{MINIMUM}$, $\text{MAXIMUM}$, $\text{PREDECESSOR}$, and $\text{SUCCESSOR}$ on elements drawn from a universe with size $u$ in $O(\lg\lg u)$ worst-case time. The $\text{INSERT}$ and $\text{DELETE}$ operations take $O(\lg\lg u)$ amortized time. Like reduced-space van Emde Boas trees (see Problem 20-1), yfast tries use only $O(n)$ space to store $n$ elements. The design of $y$-fast tries relies on perfect hashing (see Section 11.</description>
    </item>
    
    <item>
      <title>20.1 Preliminary approaches</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.1/</guid>
      <description>20.1-1  Modify the data structures in this section to support duplicate keys.
 To modify these structure to allow for multiple elements, instead of just storing a bit in each of the entries, we can store the head of a linked list representing how many elements of that value that are contained in the structure, with a $\text{NIL}$ value to represent having no elements of that value.
20.1-2  Modify the data structures in this section to support keys that have associated satellite data.</description>
    </item>
    
    <item>
      <title>20.2 A recursive structure</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.2/</guid>
      <description>20.2-1  Write pseudocode for the procedures $\text{PROTO-vEB-MAXIMUM}$ and $\text{PROTO-vEB-PREDECESSOR}$.
 See the two algorithms, $\text{PROTO-vEB-MAXIMUM}$ and $\text{PROTO-vEB-PREDECESSOR}$.
20.2-2  Write pseudocode for $\text{PROTO-vEB-DELETE}$. It should update the appropriate summary bit by scanning the related bits within the cluster. What is the worst-case running time of your procedure?
 PROTO-vEB-DELETE(V, x) if V.u == 2 V.A[x] = 0 else PROTO-vEB-DELETE(V.cluster[high(x)], low(x)) inCluster = FALSE for i = high(x)．sqrt(u) to (high(x) + 1)．sqrt(u) - 1 if PROTO-vEB-MEMBER(V.</description>
    </item>
    
    <item>
      <title>20.3 The van Emde Boas tree</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap20/20.3/</guid>
      <description>20.3-1  Modify vEB trees to support duplicate keys.
 To support duplicate keys, for each $u = 2$ vEB tree, instead of storing just a bit in each of the entries of its array, it should store an integer representing how many elements of that value the vEB contains.
20.3-2  Modify vEB trees to support keys that have associated satellite data.
 For any key which is a minimum on some vEB, we&amp;rsquo;ll need to store its satellite data with the min value since the key doesn&amp;rsquo;t appear in the subtree.</description>
    </item>
    
    <item>
      <title>21-1 Off-line minimum</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-1/</guid>
      <description>The off-line minimum problem asks us to maintain a dynamic set $T$ of elements from the domain ${1, 2, \ldots, n}$ under the operations $\text{INSERT}$ and $\text{EXTRACT-MIN}$. We are given a sequence $S$ of $n$ $\text{INSERT}$ and $m$ $\text{EXTRACT-MIN}$ calls, where each key in ${1, 2, \ldots, n}$ is inserted exactly once. We wish to determine which key is returned by each $\text{EXTRACT-MIN}$ call. Specifically, we wish to fill in an array $extracted[1 \ldots m]$, where for $i = 1, 2, \ldots, m$, $extracted[i]$ is the key returned by the $i$th $\text{EXTRACT-MIN}$ call.</description>
    </item>
    
    <item>
      <title>21-2 Depth determination</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-2/</guid>
      <description>In the depth-determination problem, we maintain a forest $\mathcal F = {T_i}$ of rooted trees under three operations:
$\text{MAKE-TREE}(v)$ creates a tree whose only node is $v$.
$\text{FIND-DEPTH}(v)$ returns the depth of node $v$ within its tree.
$\text{GRAFT}(r, v)$ makes node $r$, which is assumed to be the root of a tree, become the child of node $v$, which is assumed to be in a different tree than $r$ but may or may not itself be a root.</description>
    </item>
    
    <item>
      <title>21-3 Tarjan&#39;s off-line least-common-ancestors algorithm</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/problems/21-3/</guid>
      <description>The least common ancestor of two nodes $u$ and $v$ in a rooted tree $T$ is the node $w$ that is an ancestor of both $u$ and $v$ and that has the greatest depth in $T$. In the off-line least-common-ancestors problem, we are given a rooted tree $T$ and an arbitrary set $P = {{u, v}}$ of unordered pairs of nodes in $T$, and we wish to determine the least common ancestor of each pair in $P$.</description>
    </item>
    
    <item>
      <title>21.1 Disjoint-set operations</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.1/</guid>
      <description>21.1-1  Suppose that CONNECTED-COMPONENTS is run on the undirected graph $G = (V, E)$, where $V = {a, b, c, d, e, f, g, h, i, j, k}$ and the edges of $E$ are processed in the order $(d, i)$, $(f, k)$, $(g, i)$, $(b, g)$, $(a, h)$, $(i, j)$, $(d, k)$, $(b, j)$, $(d, f)$, $(g, j)$, $(a, e)$. List the vertices in each connected component after each iteration of lines 3–5.</description>
    </item>
    
    <item>
      <title>21.2 Linked-list representation of disjoint sets</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.2/</guid>
      <description>21.2-1  Write pseudocode for $\text{MAKE-SET}$, $\text{FIND-SET}$, and $\text{UNION}$ using the linked-list representation and the weighted-union heuristic. Make sure to specify the attributes that you assume for set objects and list objects.
 The three algorithms follow the english description and are provided here. There are alternate versions using the weighted union heuristic, suffixed with $\text{WU}$.
MAKE-SET(x) let o be an object with three fields, next, value, and set let L be a linked list object with head = tail = o o.</description>
    </item>
    
    <item>
      <title>21.3 Disjoint-set forests</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.3/</guid>
      <description>21.3-1  Redo Exercise 21.2-2 using a disjoint-set forest with union by rank and path compression.
 21.3-2  Write a nonrecursive version of $\text{FIND-SET}$ with path compression.
 To implement $\text{FIND-SET}$ nonrecursively, let $x$ be the element we call the function on. Create a linked list $A$ which contains a pointer to $x$. Each time we most one element up the tree, insert a pointer to that element into $A$.</description>
    </item>
    
    <item>
      <title>21.4 Analysis of union by rank with path compression</title>
      <link>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/v-advanced-data-structures/chap21/21.4/</guid>
      <description>21.4-1  Prove Lemma 21.4.
 The lemma states:
 For all nodes $x$, we have $x.rank \le x.p.rank$, with strict inequality if $x \ne x.p$. The value of $x.rank$ is initially $0$ and increases through time until $x \ne x.p$; from then on, $x.rank$ does not change. The value of $x.p.rank$ monotonically increases over time.
 The initial value of $x.rank$ is $0$, as it is initialized in line 2 of the $\text{MAKE-SET}(x)$ procedure.</description>
    </item>
    
    <item>
      <title>22-1 Classifying edges by breadth-first search</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-1/</guid>
      <description>A depth-first forest classifies the edges of a graph into tree, back, forward, and cross edges. A breadth-first tree can also be used to classify the edges reachable from the source of the search into the same four categories.
a. Prove that in a breadth-first search of an undirected graph, the following properties hold:
 There are no back edges and no forward edges. For each tree edge $(u, v)$, we have $v.</description>
    </item>
    
    <item>
      <title>22-2 Articulation points, bridges, and biconnected components</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-2/</guid>
      <description>Let $G = (V, E)$ be a connected, undirected graph. An articulation point of $G$ is a vertex whose removal disconnects $G$. A bridge of $G$ is an edge whose removal disconnects $G$. A biconnected component of $G$ is a maximal set of edges such that any two edges in the set lie on a common simple cycle. Figure 22.10 illustrates these definitions. We can determine articulation points, bridges, and biconnected components using depth-first search.</description>
    </item>
    
    <item>
      <title>22-3 Euler tour</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-3/</guid>
      <description>An Euler tour of a strongly connected, directed graph $G = (V, E)$ is a cycle that traverses each edge of $G$ exactly once, although it may visit a vertex more than once.
a. Show that $G$ has an Euler tour if and only if $in\text-degree(v) = out\text-degree(v)$ for each vertex $v \in V$.
b. Describe an $O(E)$-time algorithm to find an Euler tour of $G$ if one exists. ($\textit{Hint:}$ Merge edge-disjoint cycles.</description>
    </item>
    
    <item>
      <title>22-4 Reachability</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/problems/22-4/</guid>
      <description>Let $G = (V, E)$ be a directed graph in which each vertex $u \in V$ is labeled with a unique integer $L(U)$ from the set $\{1, 2, \ldots, |V|\}$. For each vertex $u \in V$, let $R(u) = \{v \in V: u \leadsto v \}$ be the set of vertices that are reachable from $u$. Define $\min(u)$ to be the vertex in $R(u)$ whose label is minimum, i.e., $\min(u)$ is the vertex $v$ such that $L(v) = \min \{L(w): w \in R(u) \}$.</description>
    </item>
    
    <item>
      <title>22.1 Representations of graphs</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.1/</guid>
      <description>22.1-1  Given an adjacency-list representation of a directed graph, how long does it take to compute the $out\text-degree$ of every vertex? How long does it take to compute the $in\text-degrees$?
 Since it seems as though the list for the neighbors of each vertex $v$ is just an undecorated list, to find the length of each would take time $O(out\text-degree(v))$. So, the total cost will be
 $$ \sum_{v \in V}O(out\text-degree(v)) = O(|E| + |V|).</description>
    </item>
    
    <item>
      <title>22.2 Breadth-first search</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.2/</guid>
      <description>22.2-1  Show the $d$ and $\pi$ values that result from running breadth-first search on the directed graph of Figure 22.2(a), using vertex $3$ as the source.
  $$ \begin{array}{c|cccccc} \text{vertex} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 \\ d &amp; \infty &amp; 3 &amp; 0 &amp; 2 &amp; 1 &amp; 1 \\ \pi &amp; \text{NIL} &amp; 4 &amp; \text{NIL} &amp; 5 &amp; 3 &amp; 3 \end{array} $$  22.</description>
    </item>
    
    <item>
      <title>22.3 Depth-first search</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.3/</guid>
      <description>22.3-1  Make a 3-by-3 chart with row and column labels $\text{WHITE}$, $\text{GRAY}$, and $\text{BLACK}$. In each cell $(i, j)$, indicate whether, at any point during a depth-first search of a directed graph, there can be an edge from a vertex of color $i$ to a vertex of color $j$. For each possible edge, indicate what edge types it can be. Make a second such chart for depth-first search of an undirected graph.</description>
    </item>
    
    <item>
      <title>22.4 Topological sort</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.4/</guid>
      <description>22.4-1  Show the ordering of vertices produced by $\text{TOPOLOGICAL-SORT}$ when it is run on the dag of Figure 22.8, under the assumption of Exercise 22.3-2.
 Our start and finish times from performing the $\text{DFS}$ are
 $$ \begin{array}{ccc} \text{label} &amp; d &amp; f \\ m &amp; 1 &amp; 20 \\ q &amp; 2 &amp; 5 \\ t &amp; 3 &amp; 4 \\ r &amp; 6 &amp; 19 \\ u &amp; 7 &amp; 8 \\ y &amp; 9 &amp; 18 \\ v &amp; 10 &amp; 17 \\ w &amp; 11 &amp; 14 \\ z &amp; 12 &amp; 13 \\ x &amp; 15 &amp; 16 \\ n &amp; 21 &amp; 26 \\ o &amp; 22 &amp; 25 \\ s &amp; 24 &amp; 24 \\ p &amp; 27 &amp; 28 \end{array} $$  And so, by reading off the entries in decreasing order of finish time, we have the sequence $p, n, o, s, m, r, y, v, x, w, z, u, q, t$.</description>
    </item>
    
    <item>
      <title>22.5 Strongly connected components</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap22/22.5/</guid>
      <description>22.5-1  How can the number of strongly connected components of a graph change if a new edge is added?
 It can either stay the same or decrease. To see that it is possible to stay the same, just suppose you add some edge to a cycle. To see that it is possible to decrease, suppose that your original graph is on three vertices, and is just a path passing through all of them, and the edge added completes this path to a cycle.</description>
    </item>
    
    <item>
      <title>23-1 Second-best minimum spanning tree</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-1/</guid>
      <description>Let $G = (V, E)$ be an undirected, connected graph whose weight function is $w: E \rightarrow \mathbb R$, and suppose that $|E| \ge |V|$ and all edge weights are distinct.
We define a second-best minimum spanning tree as follows. Let $\mathcal T$ be the set of all spanning trees of $G$, and let $T^\prime$ be a minimum spanning tree of $G$. Then a second-best minimum spanning tree is a spanning tree $T$ such that $W(T) = \min_{T^{\prime\prime} \in \mathcal T - \{T^\prime\}} \{w(T^{\prime\prime})\}$.</description>
    </item>
    
    <item>
      <title>23-2 Minimum spanning tree in sparse graphs</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-2/</guid>
      <description>For a very sparse connected graph $G = (V, E)$, we can further improve upon the $O(E + V\lg V)$ running time of Prim&amp;rsquo;s algorithm with Fibonacci heaps by preprocessing $G$ to decrease the number of vertices before running Prim&amp;rsquo;s algorithm. In particular, we choose, for each vertex $u$, the minimum-weight edge $(u, v)$ incident on $u$, and we put $(u, v)$ into the minimum spanning tree under construction. We then contract all chosen edges (see Section B.</description>
    </item>
    
    <item>
      <title>23-3 Bottleneck spanning tree</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-3/</guid>
      <description>A bottleneck spanning tree $T$ of an undirected graph $G$ is a spanning tree of $G$ whose largest edge weight is minimum over all spanning trees of $G$. We say that the value of the bottleneck spanning tree is the weight of the maximum-weight edge in $T$.
a. Argue that a minimum spanning tree is a bottleneck spanning tree.
Part (a) shows that finding a bottleneck spanning tree is no harder than finding a minimum spanning tree.</description>
    </item>
    
    <item>
      <title>23-4 Alternative minimum-spanning-tree algorithms</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/problems/23-4/</guid>
      <description>In this problem, we give pseudocode for three different algorithms. Each one takes a connected graph and a weight function as input and returns a set of edges $T$. For each algorithm, either prove that $T$ is a minimum spanning tree or prove that $T$ is not a minimum spanning tree. Also describe the most efficient implementation of each algorithm, whether or not it computes a minimum spanning tree.</description>
    </item>
    
    <item>
      <title>23.1 Growing a minimum spanning tree</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/23.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/23.1/</guid>
      <description>23.1-1  Let $(u, v)$ be a minimum-weight edge in a connected graph $G$. Show that $(u, v)$ belongs to some minimum spanning tree of $G$.
 Theorem 23.1 shows this.
Let $A$ be the empty set and $S$ be any set containing $u$ but not $v$.
23.1-2  Professor Sabatier conjectures the following converse of Theorem 23.1. Let $G = (V, E)$ be a connected, undirected graph with a real-valued weight function $w$ defined on $E$.</description>
    </item>
    
    <item>
      <title>23.2 The algorithms of Kruskal and Prim</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/23.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap23/23.2/</guid>
      <description>23.2-1  Kruskal&amp;rsquo;s algorithm can return different spanning trees for the same input graph $G$, depending on how it breaks ties when the edges are sorted into order. Show that for each minimum spanning tree $T$ of $G$, there is a way to sort the edges of $G$ in Kruskal&amp;rsquo;s algorithm so that the algorithm returns $T$.
 Suppose that we wanted to pick $T$ as our minimum spanning tree.</description>
    </item>
    
    <item>
      <title>24-1 Yen&#39;s improvement to Bellman-Ford</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-1/</guid>
      <description>Suppose that we order the edge relaxations in each pass of the Bellman-Ford algorithm as follows. Before the first pass, we assign an arbitrary linear order $v_1, v_2, \ldots, v_{|V|}$ to the vertices of the input graph $G = (V, E)$. Then, we partition the edge set $E$ into $E_f \cup E_b$, where $E_f = {(v_i, v_j) \in E: i &amp;lt; j}$ and $E_b = {(v_i, v_j) \in E: i &amp;gt; j}$.</description>
    </item>
    
    <item>
      <title>24-2 Nesting boxes</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-2/</guid>
      <description>A $d$-dimensional box with dimensions $(x_1, x_2, \ldots, x_d)$ nests within another box with dimensions $(y_1, y_2, \ldots, y_d)$ if there exists a permutation $\pi$ on $\{1, 2, \ldots, d\}$ such that $x_{\pi(1)} &amp;lt; y_1$, $x_{\pi(2)} &amp;lt; y_2$, $\ldots$, $x_{\pi(d)} &amp;lt; y_d$.
a. Argue that the nesting relation is transitive.
b. Describe an efficient method to determine whether or not one $d$-dimensional box nests inside another.
c. Suppose that you are given a set of $n$ $d$-dimensional boxes $\{B_1, B_2, \ldots, B_n\}$.</description>
    </item>
    
    <item>
      <title>24-3 Arbitrage</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-3/</guid>
      <description>Arbitrage is the use of discrepancies in currency exchange rates to transform one unit of a currency into more than one unit of the same currency. For example, suppose that $1$ U.S. dollar buys $49$ Indian rupees, $1$ Indian rupee buys $2$ Japanese yen, and $1$ Japanese yen buys $0.0107$ U.S. dollars. Then, by converting currencies, a trader can start with $1$ U.S. dollar and buy $49 \times 2 \times 0.</description>
    </item>
    
    <item>
      <title>24-4 Gabow&#39;s scaling algorithm for single-source shortest paths</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-4/</guid>
      <description>A scaling algorithm solves a problem by initially considering only the highestorder bit of each relevant input value (such as an edge weight). It then refines the initial solution by looking at the two highest-order bits. It progressively looks at more and more high-order bits, refining the solution each time, until it has examined all bits and computed the correct solution.
In this problem, we examine an algorithm for computing the shortest paths from a single source by scaling edge weights.</description>
    </item>
    
    <item>
      <title>24-5 Karp&#39;s minimum mean-weight cycle algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-5/</guid>
      <description>Let $G = (V, E)$ be a directed graph with weight function $w: E \to \mathbb R$, and let $n = |V|$. We define the mean weight of a cycle $c = \langle e_1, e_2, \ldots, e_k \rangle$ of edges in $E$ to be
 $$ \mu(c) = \frac{1}{k} \sum_{i = 1}^k w(e_i). $$  Let $\mu^* = \min_c \mu(c)$, where $c$ ranges over all directed cycles in $G$. We call a cycle $c$ for which $\mu(c) = \mu^*$ a minimum mean-weight cycle.</description>
    </item>
    
    <item>
      <title>24-6 Bitonic shortest paths</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/problems/24-6/</guid>
      <description>A sequence is bitonic if it monotonically increases and then monotonically decreases, or if by a circular shift it monotonically increases and then monotonically decreases. For example the sequences $\langle 1, 4, 6, 8, 3, -2 \rangle$, $\langle 9, 2, -4, -10, -5 \rangle$, and $\langle 1, 2, 3, 4 \rangle$ are bitonic, but $\langle 1, 3, 12, 4, 2, 10 \rangle$ is not bitonic. (See Problem 15-3 for the bitonic euclidean traveling-salesman problem.</description>
    </item>
    
    <item>
      <title>24.1 The Bellman-Ford algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.1/</guid>
      <description>24.1-1  Run the Bellman-Ford algorithm on the directed graph of Figure 24.4, using vertex $z$ as the source. In each pass, relax edges in the same order as in the figure, and show the $d$ and $\pi$ values after each pass. Now, change the weight of edge $(z, x)$ to $4$ and run the algorithm again, using $s$ as the source.
  $$ \begin{array}{c|ccccc} &amp; s &amp; t &amp; x &amp; y &amp; z \\ d &amp; 2 &amp; 4 &amp; 6 &amp; 9 &amp; 0 \\ \pi &amp; z &amp; x &amp; y &amp; z &amp; \text{NIL} \end{array} $$   $$ \begin{array}{c|ccccc} &amp; s &amp; t &amp; x &amp; y &amp; z \\ d &amp; 0 &amp; 0 &amp; 2 &amp; 7 &amp; -2 \\ \pi &amp; \text{NIL} &amp; x &amp; z &amp; s &amp; t \end{array} $$  24.</description>
    </item>
    
    <item>
      <title>24.2 Single-source shortest paths in directed acyclic graphs</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.2/</guid>
      <description>24.2-1  Run $\text{DAG-SHORTEST-PATHS}$ on the directed graph of Figure 24.5, using vertex $r$ as the source.
  $d$ values:
 $$ \begin{array}{cccccc} r &amp; s &amp; t &amp; x &amp; y &amp; z \\ 0 &amp; \infty &amp; \infty &amp; \infty &amp; \infty &amp; \infty \\ 0 &amp; 5 &amp; 3 &amp; \infty &amp; \infty &amp; \infty \\ 0 &amp; 5 &amp; 3 &amp; 11 &amp; \infty &amp; \infty \\ 0 &amp; 5 &amp; 3 &amp; 10 &amp; 7 &amp; 5 \\ 0 &amp; 5 &amp; 3 &amp; 10 &amp; 7 &amp; 5 \\ 0 &amp; 5 &amp; 3 &amp; 10 &amp; 7 &amp; 5 \end{array} $$  $\pi$ values:</description>
    </item>
    
    <item>
      <title>24.3 Dijkstra&#39;s algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.3/</guid>
      <description>24.3-1  Run Dijkstra&amp;rsquo;s algorithm on the directed graph of Figure 24.2, first using vertex $s$ as the source and then using vertex $z$ as the source. In the style of Figure 24.6, show the $d$ and $\pi$ values and the vertices in set $S$ after each iteration of the while loop.
  $s$ as the source:
 $d$ values:   $$ \begin{array}{ccccc} s &amp; t &amp; x &amp; y &amp; z \\ 0 &amp; 3 &amp; \infty &amp; 5 &amp; \infty \\ 0 &amp; 3 &amp; 9 &amp; 5 &amp; \infty \\ 0 &amp; 3 &amp; 9 &amp; 5 &amp; 11 \\ 0 &amp; 3 &amp; 9 &amp; 5 &amp; 11 \\ 0 &amp; 3 &amp; 9 &amp; 5 &amp; 11 \end{array} $$   $\pi$ values:   $$ \begin{array}{ccccc} s &amp; t &amp; x &amp; y &amp; z \\ \text{NIL} &amp; s &amp; \text{NIL} &amp; \text{NIL} &amp; \text{NIL} \\ \text{NIL} &amp; s &amp; t &amp; s &amp; \text{NIL} \\ \text{NIL} &amp; s &amp; t &amp; s &amp; y \\ \text{NIL} &amp; s &amp; t &amp; s &amp; y \\ \text{NIL} &amp; s &amp; t &amp; s &amp; y \end{array} $$  $z$ as the source:</description>
    </item>
    
    <item>
      <title>24.4 Difference constraints and shortest paths</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.4/</guid>
      <description>24.4-1  Find a feasible solution or determine that no feasible solution exists for the following system of difference constraints:
 $$ \begin{aligned} x_1 - x_2 &amp; \le &amp; 1, \\ x_1 - x_4 &amp; \le &amp; -4, \\ x_2 - x_3 &amp; \le &amp; 2, \\ x_2 - x_5 &amp; \le &amp; 7, \\ x_2 - x_6 &amp; \le &amp; 5, \\ x_3 - x_6 &amp; \le &amp; 10, \\ x_4 - x_2 &amp; \le &amp; 2, \\ x_5 - x_1 &amp; \le &amp; -1, \\ x_5 - x_4 &amp; \le &amp; 3, \\ x_6 - x_3 &amp; \le &amp; 8 \\ \end{aligned} $$   Our vertices of the constraint graph will be</description>
    </item>
    
    <item>
      <title>24.5 Proofs of shortest-paths properties</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap24/24.5/</guid>
      <description>24.5-1  Give two shortest-paths trees for the directed graph of Figure 24.2 (on page 648) other than the two shown.
 Since the induced shortest path trees on $\{s, t, y\}$ and on $\{t, x, y, z\}$ are independent and have to possible configurations each, there are four total arising from that. So, we have the two not shown in the figure are the one consisting of the edges $\{(s, t), (s, y), (y, x), (x, z)\}$ and the one consisting of the edges $\{(s, t), (t, y), (t, x), (y, z)\}$.</description>
    </item>
    
    <item>
      <title>25-1 Transitive closure of a dynamic graph</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/problems/25-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/problems/25-1/</guid>
      <description>Suppose that we wish to maintain the transitive closure of a directed graph $G = (V, E)$ as we insert edges into $E$. That is, after each edge has been inserted, we want to update the transitive closure of the edges inserted so far. Assume that the graph $G$ has no edges initially and that we represent the transitive closure as a boolean matrix.
a. Show how to update the transitive closure $G^* = (V, E^*)$ of a graph $G = (V, E)$ in $O(V^2)$ time when a new edge is added to $G$.</description>
    </item>
    
    <item>
      <title>25-2 Shortest paths in epsilon-dense graphs</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/problems/25-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/problems/25-2/</guid>
      <description>A graph $G = (V, E)$ is $\epsilon$-dense if $|E| = \Theta(V^{1 + \epsilon})$ for some constant $\epsilon$ in the range $0 &amp;lt; \epsilon \le 1$. By using $d$-ary min-heaps (see Problem 6-2) in shortest-paths algorithms on $\epsilon$-dense graphs, we can match the running times of Fibonacci-heap-based algorithms without using as complicated a data structure.
a. What are the asymptotic running times for $\text{INSERT}$, $\text{EXTRACT-MIN}$, and $\text{DECREASE-KEY}$, as a function of $d$ and the number $n$ of elements in a $d$-ary min-heap?</description>
    </item>
    
    <item>
      <title>25.1 Shortest paths and matrix multiplication</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.1/</guid>
      <description>25.1-1  Run $\text{SLOW-ALL-PAIRS-SHORTEST-PATHS}$ on the weighted, directed graph of Figure 25.2, showing the matrices that result for each iteration of the loop. Then do the same for $\text{FASTER-ALL-PAIRS-SHORTEST-PATHS}$.
  Initial:
 $$ \begin{pmatrix} 0 &amp; \infty &amp; \infty &amp; \infty &amp; -1 &amp; \infty \\ 1 &amp; 0 &amp; \infty &amp; 2 &amp; \infty &amp; \infty \\ \infty &amp; 2 &amp; 0 &amp; \infty &amp; \infty &amp; -8 \\ -4 &amp; \infty &amp; \infty &amp; 0 &amp; 3 &amp; \infty \\ \infty &amp; 7 &amp; \infty &amp; \infty &amp; 0 &amp; \infty \\ \infty &amp; 5 &amp; 10 &amp; \infty &amp; \infty &amp; 0 \end{pmatrix} $$  Slow:</description>
    </item>
    
    <item>
      <title>25.2 The Floyd-Warshall algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.2/</guid>
      <description>25.2-1  Run the Floyd-Warshall algorithm on the weighted, directed graph of Figure 25.2. Show the matrix $D^{(k)}$ that results for each iteration of the outer loop.
 $k = 1$:
 $$ \begin{pmatrix} 0 &amp; \infty &amp; \infty &amp; \infty &amp; -1 &amp; \infty \\ 1 &amp; 0 &amp; \infty &amp; 2 &amp; 0 &amp; \infty \\ \infty &amp; 2 &amp; 0 &amp; \infty &amp; \infty &amp; -8 \\ -4 &amp; \infty &amp; \infty &amp; 0 &amp; -5 &amp; \infty \\ \infty &amp; 7 &amp; \infty &amp; \infty &amp; 0 &amp; \infty \\ \infty &amp; 5 &amp; 10 &amp; \infty &amp; \infty &amp; 0 \end{pmatrix} $$  $k = 2$:</description>
    </item>
    
    <item>
      <title>25.3 Johnson&#39;s algorithm for sparse graphs</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap25/25.3/</guid>
      <description>25.3-1  Use Johnson&amp;rsquo;s algorithm to find the shortest paths between all pairs of vertices in the graph of Figure 25.2. Show the values of $h$ and $\hat w$ computed by the algorithm.
  $$ \begin{array}{c|c} v &amp; h(v) \\ 1 &amp; -5 \\ 2 &amp; -3 \\ 3 &amp; 0 \\ 4 &amp; -1 \\ 5 &amp; -6 \\ 6 &amp; -8 \end{array} $$   $$ \begin{array}{ccc|ccc} u &amp; v &amp; \hat w(u, v) &amp; u &amp; v &amp; \hat w(u, v) \\ 1 &amp; 2 &amp; \text{NIL} &amp; 4 &amp; 1 &amp; 0 \\ 1 &amp; 3 &amp; \text{NIL} &amp; 4 &amp; 2 &amp; \text{NIL} \\ 1 &amp; 4 &amp; \text{NIL} &amp; 4 &amp; 3 &amp; \text{NIL} \\ 1 &amp; 5 &amp; 0 &amp; 4 &amp; 5 &amp; 8 \\ 1 &amp; 6 &amp; \text{NIL} &amp; 4 &amp; 6 &amp; \text{NIL} \\ 2 &amp; 1 &amp; 3 &amp; 5 &amp; 1 &amp; \text{NIL} \\ 2 &amp; 3 &amp; \text{NIL} &amp; 5 &amp; 2 &amp; 4 \\ 2 &amp; 4 &amp; 0 &amp; 5 &amp; 3 &amp; \text{NIL} \\ 2 &amp; 5 &amp; \text{NIL} &amp; 5 &amp; 4 &amp; \text{NIL} \\ 2 &amp; 6 &amp; \text{NIL} &amp; 5 &amp; 6 &amp; \text{NIL} \\ 3 &amp; 1 &amp; \text{NIL} &amp; 6 &amp; 1 &amp; \text{NIL} \\ 3 &amp; 2 &amp; 5 &amp; 6 &amp; 2 &amp; 0 \\ 3 &amp; 4 &amp; \text{NIL} &amp; 6 &amp; 3 &amp; 18 \\ 3 &amp; 5 &amp; \text{NIL} &amp; 6 &amp; 4 &amp; \text{NIL} \\ 3 &amp; 6 &amp; 0 &amp; 6 &amp; 5 &amp; \text{NIL} \\ \end{array} $$  So, the $d_{ij}$ values that we get are</description>
    </item>
    
    <item>
      <title>26-1 Escape problem</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-1/</guid>
      <description>A$n \times n$ grid is an undirected graph consisting of $n$ rows and $n$ columns of vertices, as shown in Figure 26.11. We denote the vertex in the $i$th row and the $j$th column by $(i, j)$. All vertices in a grid have exactly four neighbors, except for the boundary vertices, which are the points $(i, j)$ for which $i = 1$, $i = n$, $j = 1$, or $j = n$.</description>
    </item>
    
    <item>
      <title>26-2 Minimum path cover</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-2/</guid>
      <description>A path cover of a directed graph $G = (V, E)$ is a set $P$ of vertex-disjoint paths such that every vertex in $V$ is included in exactly one path in $P$. Paths may start and end anywhere, and they may be of any length, including $0$. A minimum path cover of $G$ is a path cover containing the fewest possible paths.
a. Give an efficient algorithm to find a minimum path cover of a directed acyclic graph $G = (V, E)$.</description>
    </item>
    
    <item>
      <title>26-3 Algorithmic consulting</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-3/</guid>
      <description>Professor Gore wants to open up an algorithmic consulting company. He has identified n important subareas of algorithms (roughly corresponding to different portions of this textbook), which he represents by the set $A = {A_1, A_2, \ldots, A_n}$. In each subarea $A_k$, he can hire an expert in that area for $c_k$ dollars. The consulting company has lined up a set $J = {J_1, J_2, \ldots, J_m}$ of potential jobs.</description>
    </item>
    
    <item>
      <title>26-4 Updating maximum flow</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-4/</guid>
      <description>Let $G = (V, E)$ be a flow network with source $s$, sink $t$, and integer capacities. Suppose that we are given a maximum flow in $G$.
a. Suppose that we increase the capacity of a single edge $(u, v) \in E$ by $1$. Give an $O(V + E)$-time algorithm to update the maximum flow.
b. Suppose that we decrease the capacity of a single edge $(u, v) \in E$ by $1$.</description>
    </item>
    
    <item>
      <title>26-5 Maximum flow by scaling</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-5/</guid>
      <description>Let $G = (V, E)$ be a flow network with source $s$, sink $t$, and an integer capacity $c(u, v)$ on each edge $(u, v) \in E$. Let $C = \max_{(u, v) \in E} c(u, v)$.
a. Argue that a minimum cut of $G$ has capacity at most $C|E|$.
b. For a given number $K$, show how to find an augmenting path of capacity at least $K$ in $O(E)$ time, if such a path exists.</description>
    </item>
    
    <item>
      <title>26-6 The Hopcroft-Karp bipartite matching algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/problems/26-6/</guid>
      <description>In this problem, we describe a faster algorithm, due to Hopcroft and Karp, for $p$ finding a maximum matching in a bipartite graph. The algorithm runs in $O(\sqrt V E)$ time. Given an undirected, bipartite graph $G = (V, E)$, where $V = L \cup R$ and all edges have exactly one endpoint in $L$, let $M$ be a matching in $G$. We say that a simple path $P$ in $G$ is an augmenting path with respect to $M$ if it starts at an unmatched vertex in $L$, ends at an unmatched vertex in $R$, and its edges belong alternately to $M$ and $E - M$.</description>
    </item>
    
    <item>
      <title>26.1 Flow networks</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.1/</guid>
      <description>26.1-1  Show that splitting an edge in a flow network yields an equivalent network. More formally, suppose that flow network $G$ contains edge $(u, v)$, and we create a new flow network $G^\prime$ by creating a new vertex $x$ and replacing $(u, v)$ by new edges $(u, x)$ and $(x, v)$ with $c(u, x) = c(x, v) = c(u, v)$. Show that a maximum flow in $G^\prime$ has the same value as a maximum flow in $G$.</description>
    </item>
    
    <item>
      <title>26.2 The Ford-Fulkerson method</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.2/</guid>
      <description>26.2-1  Prove that the summations in equation $\text{(26.6)}$ equal the summations in equation $\text{(26.7)}$.
 Lemma
 If $v \notin V_1$, then $f(s, v) = 0$. If $v \notin V_2$, then $f(v, s) = 0$. If $v \notin V_1 \cup V_2$, then $f^\prime(s, v) = 0$. If $v \notin V_1 \cup V_2$, then $f^\prime(v, s) = 0$.  Proof
 Let $v \notin V_1$ be some vertex. From the definition of $V_1$, there is no edge from $s$ to $v$.</description>
    </item>
    
    <item>
      <title>26.3 Maximum bipartite matching</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.3/</guid>
      <description>26.3-1  Run the Ford-Fulkerson algorithm on the flow network in Figure 26.8(c) and show the residual network after each flow augmentation. Number the vertices in $L$ top to bottom from 1 to 5 and in $R$ top to bottom from 6 to 9. For each iteration, pick the augmenting path that is lexicographically smallest.
 First, we pick an augmenting path that passes through vertices 1 and 6. Then, we pick the path going through 2 and 8.</description>
    </item>
    
    <item>
      <title>26.4 Push-relabel algorithms</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.4/</guid>
      <description>26.4-1  Prove that, after the procedure $\text{INITIALIZE-PREFLOW}(G, S)$ terminates, we have $s.e \le -|f^*|$, where $f^*$ is a maximum flow for $G$.
 We apply the definition of excess flow (equation $\text{(26.14)}$) to the initial preflow $f$ created by $\text{INITIALIZE-PREFLOW}$ (equation $\text{(26.15)}$) to obtain
 $$ \begin{aligned} e(s) &amp; = \sum_{v \in V} f(v, s) - \sum_{v \in V} f(s, v) \\ &amp; = 0 - \sum_{v \in V} c(s, v) \\ &amp; = -\sum_{v \in V} c(s, v).</description>
    </item>
    
    <item>
      <title>26.5 The relabel-to-front algorithm</title>
      <link>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vi-graph-algorithms/chap26/26.5/</guid>
      <description>26.5-1  Illustrate the execution of $\text{RELABEL-TO-FRONT}$ in the manner of Figure 26.10 for the flow network in Figure 26.1(a). Assume that the initial ordering of vertices in $L$ is $\langle v_1, v_2, v_3, v_4 \rangle$ and that the neighbor lists are
 $$ \begin{aligned} v_1.N &amp; = \langle s, v_2, v_3 \rangle, \\ v_2.N &amp; = \langle s, v_1, v_3, v_4 \rangle, \\ v_3.N &amp; = \langle v_1, v_2, v_4, t \rangle, \\ v_4.</description>
    </item>
    
    <item>
      <title>27-1 Implementing parallel loops using nested parallelism</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-1/</guid>
      <description>Consider the following multithreaded algorithm for performing pairwise addition on $n$-element arrays $A[1..n]$ and $B[1..n]$, storing the sums in $C[1..n]$:
SUM-ARRAYS(A, B, C) parallel for i = 1 to A.length C[i] = A[i] + B[i]  a. Rewrite the parallel loop in $\text{SUM-ARRAYS}$ using nested parallelism (spawn and sync) in the manner of $\text{MAT-VEC-MAIN-LOOP}$. Analyze the parallelism of your implementation.
Consider the following alternative implementation of the parallel loop, which contains a value $grain\text-size$ to be specified:</description>
    </item>
    
    <item>
      <title>27-2 Saving temporary space in matrix multiplication</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-2/</guid>
      <description>The $\text{P-MATRIX-MULTIPLY-RECURSIVE}$ procedure has the disadvantage that it must allocate a temporary matrix $T$ of size $n \times n$, which can adversely affect the constants hidden by the $\Theta$-notation. The $\text{P-MATRIX-MULTIPLY-RECURSIVE}$ procedure does have high parallelism, however. For example, ignoring the constants in the $\Theta$-notation, the parallelism for multiplying $1000 \times 1000$ matrices comes to approximately $1000^3 / 10^2 = 10^7$, since $\lg 1000 \approx 10$. Most parallel computers have far fewer than 10 million processors.</description>
    </item>
    
    <item>
      <title>27-3 Multithreaded matrix algorithms</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-3/</guid>
      <description> a. Parallelize the $\text{LU-DECOMPOSITION}$ procedure on page 821 by giving pseudocode for a multithreaded version of this algorithm. Make your implementation as parallel as possible, and analyze its work, span, and parallelism.
b. Do the same for $\text{LUP-DECOMPOSITION}$ on page 824.
c. Do the same for $\text{LUP-SOLVE}$ on page 817.
d. Do the same for a multithreaded algorithm based on equation $\text{(28.13)}$ for inverting a symmetric positive-definite matrix.
 </description>
    </item>
    
    <item>
      <title>27-4 Multithreading reductions and prefix computations</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-4/</guid>
      <description>A $\otimes$-reduction of an array $x[1 \ldots n]$, where $\otimes$ is an associative operator, is the value
 $$ y = x[1] \otimes x[2] \otimes \cdots \otimes x[n] $$  The following procedure computes the $\otimes$-reduction of a subarray $x[i \ldots j]$ serially.
REDUCE(x, i, j) y = x[i] for k = i + 1 to j y = y ⊗ x[k] return y  a. Use nested parallelism to implement a multithreaded algorithm $\text{P-REDUCE}$, which performs the same function with $\Theta(n)$ work and $\Theta(\lg n)$ span.</description>
    </item>
    
    <item>
      <title>27-5 Multithreading a simple stencil calculation</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-5/</guid>
      <description>Computational science is replete with algorithms that require the entries of an array to be filled in with values that depend on the values of certain already computed neighboring entries, along with other information that does not change over the course of the computation. The pattern of neighboring entries does not change during the computation and is called a stencil. For example, Section 15.4 presents a stencil algorithm to compute a longest common subsequence, where the value in entry $c[i, j]$ depends only on the values in $c[i - 1, j]$, $c[i, j - 1]$, and $c[i - 1, j - 1]$, as well as the elements $x_i$ and $y_j$ within the two sequences given as inputs.</description>
    </item>
    
    <item>
      <title>27-6 Randomized multithreaded algorithms</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/problems/27-6/</guid>
      <description>Just as with ordinary serial algorithms, we sometimes want to implement randomized multithreaded algorithms. This problem explores how to adapt the various performance measures in order to handle the expected behavior of such algorithms. It also asks you to design and analyze a multithreaded algorithm for randomized quicksort.
a. Explain how to modify the work law $\text{(27.2)}$, span law $\text{(27.3)}$, and greedy scheduler bound $\text{(27.4)}$ to work with expectations when $T_P$, $T_1$, and $T_\infty$ are all random variables.</description>
    </item>
    
    <item>
      <title>27.1 The basics of dynamic multithreading</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.1/</guid>
      <description>27.1-1  Suppose that we spawn $\text{P-FIB}(n - 2)$ in line 4 of $\text{P-FIB}$, rather than calling it as is done in the code. What is the impact on the asymptotic work, span, and parallelism?
 There will be no change in the asymptotic work, span, or parallelism of $\text{P-FIB}$ even if we were to spawn the recursive call to $\text{P-FIB}(n - 2)$. The serialization of $\text{P-FIB}$ under consideration would yield the same recurrence as that for $\text{FIB}$; we can, therefore, calculate the work as $T_1(n) = \Theta(\phi^n)$.</description>
    </item>
    
    <item>
      <title>27.2 Multithreaded matrix multiplication</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.2/</guid>
      <description>27.2-1  Draw the computation dag for computing $\text{P-SQUARE-MATRIX-MULTIPLY}$ on $2 \times 2$ matrices, labeling how the vertices in your diagram correspond to strands in the execution of the algorithm. Use the convention that spawn and call edges point downward, continuation edges point horizontally to the right, and return edges point upward. Assuming that each strand takes unit time, analyze the work, span, and parallelism of this computation.
 27.</description>
    </item>
    
    <item>
      <title>27.3 Multithreaded merge sort</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap27/27.3/</guid>
      <description>27.3-1  Explain how to coarsen the base case of $\text{P-MERGE}$.
 Replace the condition on line 2 with a check that $n &amp;lt; k$ for some base case size $k$. And instead of just copying over the particular element of $A$ to the right spot in $B$, you would call a serial sort on the remaining segment of $A$ and copy the result of that over into the right spots in $B$.</description>
    </item>
    
    <item>
      <title>28-1 Tridiagonal systems of linear equations</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/problems/28-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/problems/28-1/</guid>
      <description>Consider the tridiagonal matrix
 $$ A = \begin{pmatrix} 1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\ -1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 2 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; -1 &amp; 2 &amp; -1 \\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 2 \end{pmatrix}. $$  a. Find an $\text{LU}$ decomposition of $A$.
b. Solve the equation $Ax = \begin{pmatrix} 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \end{pmatrix}^{\text T}$ by using forward and back substitution.</description>
    </item>
    
    <item>
      <title>28-2 Splines</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/problems/28-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/problems/28-2/</guid>
      <description>A pratical method for interpolating a set of points with a curve is to use cubic splines. We are given a set ${(x_i, y_i): i = 0, 1, \ldots, n}$ of $n + 1$ point-value pairs, where $x_0 &amp;lt; x_1 &amp;lt; \cdots &amp;lt; x_n$. We wish to fit a piecewise-cubic curve (spline) $f(x)$ to the points. That is, the curve $f(x)$ is made up of $n$ cubic polynomials $f_i(x) = a_i + b_ix + c_ix^2 + d_ix^3$ for $i = 0, 1, \ldots, n - 1$, where if $x$ falls in the range $x_i \le x \le x_{i + 1}$, then the value of the curve is given by $f(x) = f_i(x - x_i)$.</description>
    </item>
    
    <item>
      <title>28.1 Solving systems of linear equations</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.1/</guid>
      <description>28.1-1  Solve the equation
 $$ \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 4 &amp; 1 &amp; 0 \\ -6 &amp; 5 &amp; 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 3 \\ 14 \\ -7 \end{pmatrix} $$  by using forward substitution.
 28.1-2  Find an $\text{LU}$ decomposition of the matrix
 $$ \begin{pmatrix} 4 &amp; -5 &amp; 6 \\ 8 &amp; -6 &amp; 7 \\ 12 &amp; -7 &amp; 12 \end{pmatrix}.</description>
    </item>
    
    <item>
      <title>28.2 Inverting matrices</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.2/</guid>
      <description>28.2-1  Let $M(n)$ be the time to multiply two $n \times n$ matrices, and let $S(n)$ denote the time required to square an $n \times n$ matrix. Show that multiplying and squaring matrices have essentially the same difficulty: an $M(n)$-time matrix-multiplication algorithm implies an $O(M(n))$-time squaring algorithm, and an $S(n)$-time squaring algorithm implies an $O(S(n))$-time matrix-multiplication algorithm.
 28.2-2  Let $M(n)$ be the time to multiply two $n \times n$ matrices, and let $L(n)$ be the time to compute the LUP decomposition of an $n \times n$ matrix.</description>
    </item>
    
    <item>
      <title>28.3 Symmetric positive-definite matrices and least-squares approximation</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap28/28.3/</guid>
      <description>28.3-1  Prove that every diagonal element of a symmetric positive-definite matrix is positive.
 28.3-2  Let
 $$ A = \begin{pmatrix} a &amp; b \\ b &amp; c \end{pmatrix} $$  be a $2 \times 2$ symmetrix positive-definite matrix. Prove that its determinant $ac - b^2$ is positive by &amp;ldquo;completing the square&amp;rdquo; in a manner similar to that used in the proof of Lemma 28.5.
 28.3-3  Prove that the maximum element in a symmetric positive-definite matrix lies on the diagonal.</description>
    </item>
    
    <item>
      <title>29-1 Linear-inequality feasibility</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>29-2 Complementary slackness</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>29-3 Integer linear programming</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>29-4 Farkas&#39;ss lemma</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>29-5 Minimum-cost circulation</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/problems/29-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>29.1 Standard and slack forms</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.1/</guid>
      <description>29.1-1  If we express the linear program in $\text{(29.24)}$–$\text{(29.28)}$ in the compact notation of $\text{(29.19)}$–$\text{(29.21)}$, what are $n$, $m$, $A$, $b$, and $c$?
 29.1-2  Give three feasible solutions to the linear program in $\text{(29.24)}$–$\text{(29.28)}$. What is the objective value of each one?
 29.1-3  For the slack form in $\text{(29.38)}$–$\text{(29.41)}$, what are $N$, $B$, $A$, $b$, $c$, and $v$?
 29.1-4  Convert the following linear program into standard form:</description>
    </item>
    
    <item>
      <title>29.2 Formulating problems as linear programs</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.2/</guid>
      <description>29.2-1  Put the single-pair shortest-path linear program from $\text{(29.44)}$–$\text{(29.46)}$ into standard form.
 29.2-2  Write out explicitly the linear program corresponding to finding the shortest path from node $s$ to node $y$ in Figure 24.2(a).
 29.2-3  In the single-source shortest-paths problem, we want to find the shortest-path weights from a source vertex $s$ to all vertices $v \in V$. Given a graph $G$, write a linear program for which the solution has the property that $d_v$ is the shortest-path weight from $s$ to $v$ for each vertex $v \in V$.</description>
    </item>
    
    <item>
      <title>29.3 The simplex algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.3/</guid>
      <description>29.3-1  Complete the proof of Lemma 29.4 by showing that it must be the case that $c = c&amp;rsquo;$ and $v = v&amp;rsquo;$.
 29.3-2  Show that the call to $\text{PIVOT}$ in line 12 of $\text{SIMPLEX}$ never decreases the value of $v$.
 29.3-3  Prove that the slack form given to the $\text{PIVOT}$ procedure and the slack form that the procedure returns are equivalent.
 29.3-4  Suppose we convert a linear program $(A, b, c)$ in standard form to slack form.</description>
    </item>
    
    <item>
      <title>29.4 Duality</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.4/</guid>
      <description>29.4-1  Formulate the dual of the linear program given in Exercise 29.3-5.
 29.4-2  Suppose that we have a linear program that is not in standard form. We could produce the dual by first converting it to standard form, and then taking the dual. It would be more convenient, however, to be able to produce the dual directly. Explain how we can directly take the dual of an arbitrary linear program.</description>
    </item>
    
    <item>
      <title>29.5 The initial basic feasible solution</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap29/29.5/</guid>
      <description>29.5-1  Give detailed pseudocode to implement lines 5 and 14 of $\text{INITIALIZE-SIMPLEX}$.
 29.5-2  Show that when the main loop of $\text{SIMPLEX}$ is run by $\text{INITIALIZE-SIMPLEX}$, it can never return &amp;ldquo;unbounded.&amp;rdquo;
 29.5-3  Suppose that we are given a linear program $L$ in standard form, and suppose that for both $L$ and the dual of $L$, the basic solutions associated with the initial slack forms are feasible.</description>
    </item>
    
    <item>
      <title>3-1 Asymptotic behavior of polynomials</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-1/</guid>
      <description>Let
 $$ p(n) = \sum_{i = 0}^d a_i n^i, $$  where $a_d &amp;gt; 0$, be a degree-$d$ polynomial in $n$, and let $k$ be a constant. Use the definitions of the asymptotic notations to prove the following properties.
a. If $k \ge d$, then $p(n) = O(n^k)$.
b. If $k \le d$, then $p(n) = \Omega(n^k)$.
c. If $k = d$, then $p(n) = \Theta(n^k)$.
d. If $k &amp;gt; d$, then $p(n) = o(n^k)$.</description>
    </item>
    
    <item>
      <title>3-2 Relative asymptotic growths</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-2/</guid>
      <description>Indicate for each pair of expressions $(A, B)$ in the table below, whether $A$ is $O$, $o$, $\Omega$, $\omega$, or $\Theta$ of $B$. Assume that $k \ge 1$, $\epsilon &amp;gt; 0$, and $c &amp;gt; 1$ are constants. Your answer should be in the form of the table with &amp;ldquo;yes&amp;rdquo; or &amp;ldquo;no&amp;rdquo; written in each box.
  $$ \begin{array}{ccccccc} A &amp; B &amp; O &amp; o &amp; \Omega &amp; \omega &amp; \Theta \\ \lg^k n &amp; n^\epsilon &amp; yes &amp; yes &amp; no &amp; no &amp; no \\ n^k &amp; c^n &amp; yes &amp; yes &amp; no &amp; no &amp; no \\ \sqrt n &amp; n^{\sin n} &amp; no &amp; no &amp; no &amp; no &amp; no \\ 2^n &amp; 2^{n / 2} &amp; no &amp; no &amp; yes &amp; yes &amp; no \\ n^{\lg c} &amp; c^{\lg n} &amp; yes &amp; no &amp; yes &amp; no &amp; yes \\ \lg(n!</description>
    </item>
    
    <item>
      <title>3-3 Ordering by asymptotic growth rates</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-3/</guid>
      <description>a. Rank the following functions by order of growth; that is, find an arrangement $g_1, g_2, \ldots , g_{30}$ of the functions $g_1 = \Omega(g_2), g_2 = \Omega(g_3), \ldots, g_{29} = \Omega(g_{30})$. Partition your list into equivalence classes such that functions $f(n)$ and $g(n)$ are in the same class if and only if $f(n) = \Theta(g(n))$.
 $$ \begin{array}{cccccc} \lg(\lg^{*}n) \quad &amp; \quad 2^{\lg^*n} \quad &amp; \quad (\sqrt 2)^{\lg n} \quad &amp; \quad n^2 \quad &amp; \quad n!</description>
    </item>
    
    <item>
      <title>3-4 Asymptotic notation properties</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-4/</guid>
      <description>Let $f(n)$ and $g(n)$ by asymptotically positive functions. Prove or disprove each of the following conjectures.
a. $f(n) = O(g(n))$ implies $g(n) = O(f(n))$.
b. $f(n) + g(n) = \Theta(\min(f(n), g(n)))$.
c. $f(n) = O(g(n))$ implies $\lg(f(n)) = O(\lg(g(n)))$, where $\lg(g(n)) \ge 1$ and $f(n) \ge 1$ for all sufficiently large $n$.
d. $f(n) = O(g(n))$ implies $2^{f(n)} = O(2^{g(n)})$.
e. $f(n) = O((f(n))^2)$.
f. $f(n) = O(g(n))$ implies $g(n) = \Omega(f(n))$.</description>
    </item>
    
    <item>
      <title>3-5 Variations on $O$ and Omega</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-5/</guid>
      <description>Some authors define $\Omega$ in a slightly different way than we do; let&amp;rsquo;s use ${\Omega}^{\infty}$ (read &amp;ldquo;omega infinity&amp;rdquo;) for this alternative definition. We say that $f(n) = {\Omega}^{\infty}(g(n))$ if there exists a positive constant $c$ such that $f(n) \ge cg(n) \ge 0$ for infinitely many integers $n$.
a. Show that for any two functions $f(n)$ and $g(n)$ that are asymptotically nonnegative, either $f(n) = O(g(n))$ or $f(n) = {\Omega}^{\infty}(g(n))$ or both, whereas this is not true if we use $\Omega$ in place of ${\Omega}^{\infty}$.</description>
    </item>
    
    <item>
      <title>3-6 Iterated functions</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/problems/3-6/</guid>
      <description>We can apply the iteration operator $^*$ used in the $\lg^*$ function to any monotonically increasing function $f(n)$ over the reals. For a given constant $c \in \mathbb R$, we define the iterated function ${f_c}^*$ by ${f_c}^*(n) = \min \{i \ge 0 : f^{(i)}(n) \le c \}$ which need not be well defined in all cases. In other words, the quantity ${f_c}^*(n)$ is the number of iterated applications of the function $f$ required to reduce its argument down to $c$ or less.</description>
    </item>
    
    <item>
      <title>3.1 Asymptotic notation</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/3.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/3.1/</guid>
      <description>3.1-1  Let $f(n) + g(n)$ be asymptotically nonnegative functions. Using the basic definition of $\Theta$-notation, prove that $\max(f(n), g(n)) = \Theta(f(n) + g(n))$.
 First, let&amp;rsquo;s clarify what the function $\max(f(n), g(n))$ is. Let&amp;rsquo;s define the function $h(n) = \max(f(n), g(n))$. Then
 $$ h(n) = \begin{cases} f(n) &amp; \text{ if } f(n) \ge g(n), \\ g(n) &amp; \text{ if } f(n) Since $f(n)$ and $g(n)$ are asymptotically nonnegative, there exists $n_0$ such that $f(n) \ge 0$ and $g(n) \ge 0$ for all $n \ge n_0$.</description>
    </item>
    
    <item>
      <title>3.2 Standard notations and common functions</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap03/3.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap03/3.2/</guid>
      <description>3.2-1  Show that if $f(n)$ and $g(n)$ are monotonically increasing functions, then so are the functions $f(n) + g(n)$ and $f(g(n))$, and if $f(n)$ and $g(n)$ are in addition nonnegative, then $f(n) \cdot g(n)$ is monotonically increasing.
  $$ \begin{aligned} f(m) \le f(n) \quad \text{ for } m \le n \\ g(m) \le g(n) \quad \text{ for } m \le n, \\ \to f(m) + g(m) \le f(n) + g(n), \end{aligned} $$  which proves the first function.</description>
    </item>
    
    <item>
      <title>30-1 Divide-and-conquer multiplication</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30-2 Toeplitz matrices</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30-3 Multidimensional fast Fourier transform</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30-4 Evaluating all derivatives of a polynomial at a point</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30-5 Polynomial evaluation at multiple points</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30-6 FFT using modular arithmetic</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/problems/30-6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30.1 Representing polynomials</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30.2 The DFT and FFT</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>30.3 Efficient FFT implementations</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap30/30.3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>31-1 Binary gcd algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-1/</guid>
      <description>Most computers can perform the operations of subtraction, testing the parity (odd or even) of a binary integer, and halving more quickly than computing remainders. This problem investigates the binary gcd algorithm, which avoids the remainder computations used in Euclid&amp;rsquo;s algorithm.
a. Prove that if $a$ and $b$ are both even, then $\text{gcd}(a, b) = 2 \cdot \text{gcd}(a/2, b/2)$.
b. Prove that if $a$ is odd and $b$ is even, then $\text{gcd}(a, b) = \text{gcd}(a, b/2)$.</description>
    </item>
    
    <item>
      <title>31-2 Analysis of bit operations in Euclid&#39;s algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-2/</guid>
      <description>a. Consider the ordinary &amp;ldquo;paper and pencil&amp;rdquo; algorithm for long division: dividing $a$ by $b$, which yields a quotient $q$ and remainder $r$. Show that this method requires $O((1 + \lg q) \lg b)$ bit operations.
b. Define $\mu(a, b) = (1 + \lg a)(1 + \lg b)$. Show that the number of bit operations performed by EUCLID in reducing the problem of computing $\text{gcd}(a, b)$ to that of computing $\text{gcd}(b, a~\text{mod}~b)$ is at most $c(\mu(a, b) - \mu(b, a~\text{mod}~b))$ for some sufficiently large constant $c &amp;gt; 0$.</description>
    </item>
    
    <item>
      <title>31-3 Three algorithms for Fibonacci numbers</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-3/</guid>
      <description>This problem compares the efficiency of three methods for computing the $n$th Fibonacci number $F_n$, given $n$. Assume that the cost of adding, subtracting, or multiplying two numbers is $O(1)$, independent of the size of the numbers.
a. Show that the running time of the straightforward recursive method for computing $F_n$ based on recurrence (3.22) is exponential in $n$. (See, for example, the FIB procedure on page 775.)
b. Show how to compute $F_n$ in $O(n)$ time using memoization.</description>
    </item>
    
    <item>
      <title>31-4 Quadratic residues</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/problems/31-4/</guid>
      <description>Let $p$ be an odd prime. A number $a \in Z_p^*$ is a quadratic residue if the equation $x^2 = a ~(\text{mod}~p)$ has a solution for the unknown $x$.
a. Show that there are exactly $(p - 1) / 2$ quadratic residues, modulo $p$.
b. If $p$ is prime, we define the Legendre symbol $(\frac{a}{p})$, for $a \in \mathbb{Z}_p^$, to be $1$ if $a$ is a quadratic residue modulo $p$ and $-1$ otherwise.</description>
    </item>
    
    <item>
      <title>31.1 Elementary number-theoretic notions</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.1/</guid>
      <description>31.1-1  Prove that if $a &amp;gt; b &amp;gt; 0$ and $c = a + b$, then $c ~\text{mod}~ a = b$.
 {equation} $$\begin{array}{rll} c ~\text{mod}~ a &amp;amp;=&amp;amp; (a + b) ~\text{mod}~ a &amp;amp;=&amp;amp; (a ~\text{mod}~ a) + (b ~\text{mod}~ a) &amp;amp;=&amp;amp; 0 + b &amp;amp;=&amp;amp; b \end{array} $$  {equation}
31.1-2  Prove that there are infinitely many primes.
 {equation} $$\begin{array}{rl} &amp;amp; ((p_1 p_2 \cdots p_k) + 1) ~\text{mod}~ p_i =&amp;amp; (p_1 p_2 \cdots p_k) ~\text{mod}~ p_i + (1 ~\text{mod}~ p_i) =&amp;amp; 0 + 1 =&amp;amp; 1 \end{array} $$  {equation}</description>
    </item>
    
    <item>
      <title>31.2 Greatest common divisor</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.2/</guid>
      <description>31.2-1  Prove that equations (31.11) and (31.12) imply equation (31.13).
 31.2-2  Compute the values $(d, x, y)$ that the call EXTENDED-EUCLID$(899, 493)$ returns.
 $(29, -6, 11)$.
31.2-3  Prove that for all integers $a$, $k$, and $n$,
$\text{gcd}(a, n) = \text{gcd}(a + kn, n)$.
  $\text{gcd}(a, n) ~|~ \text{gcd}(a + kn, n){equation} Let $d = \text{gcd}(a, n)$, then $d ~|~ a$ and $d ~|~ n$.</description>
    </item>
    
    <item>
      <title>31.3 Modular arithmetic</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.3/</guid>
      <description>31.3-1  Draw the group operation tables for the groups $(\mathbb{Z}_4, +_4)$ and $(\mathbb{Z}_5^*, \cdot_5)$. Show that these groups are isomorphic by exhibiting a one-to-one correspondence $\alpha$ between their elements such that $a + b \equiv c ~(\text{mod}~4)$ if and only if $\alpha(a) \cdot \alpha(b) \equiv \alpha&amp;copy; ~(\text{mod}~5)$.
  $(\mathbb{Z}_4, +_4)$: ${ 0, 1, 2, 3 }$. $(\mathbb{Z}_5^*, \cdot_5)$: ${ 1, 2,3,4 }$.  $\alpha(x) = 2^{x-1}$.
31.3-2  List all subgroups of $\mathbb{Z}_9$ and of $\mathbb{Z}_{13}^*$.</description>
    </item>
    
    <item>
      <title>31.4 Solving modular linear equations</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.4/</guid>
      <description>31.4-1  Find all solutions to the equation $35x \equiv 10 (\text{mod}~50)$.
 ${6, 16, 26, 36, 46}$.
31.4-2  Prove that the equation $ax \equiv ay ~(\text{mod}~n)$ implies $x \equiv y ~(\text{mod}~n)$ whenever $\text{gcd}(a, n) = 1$. Show that the condition $\text{gcd}(a, n) = 1$ is necessary by supplying a counterexample with $\text{gcd}(a, n) &amp;gt; 1$.
 $d = \text{gcd}(ax, n) = \text{gcd}(x, n){equation} Since $ax \cdot x&amp;rsquo; + n \cdot y&amp;rsquo; = d$, then $x \cdot (ax&amp;rsquo;) + n \cdot y&amp;rsquo; = d$.</description>
    </item>
    
    <item>
      <title>31.5 The Chinese remainder theorem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.5/</guid>
      <description>31.5-1  Find all solutions to the equations $x \equiv 4 ~(\text{mod}~5)$ and $x \equiv 5 ~(\text{mod}~11)$.
 $m_1 = 11$, $m_2 = 5$.
$m_1^{-1} = 1$, $m_2^{-1} = 9$.
$c_1 = 11$, $c_2 = 45$.
$a = (c_1 \cdot a_1 + c_2 \cdot a_2) ~\text{mod}~ (n_1 \cdot n_2) = (11 * 4 + 45 * 5) ~\text{mod}~ 55 = 49$.
31.5-2  Find all integers $x$ that leave remainders $1, 2, 3$ when divided by $9, 8, 7$ respectively.</description>
    </item>
    
    <item>
      <title>31.6 Powers of an element</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.6/</guid>
      <description>31.6-1  Draw a table showing the order of every element in $\mathbb{Z}_{11}^$. Pick the smallest primitive root $g$ and compute a table giving $\text{ind}_{11,g}(x)$ for all $x \in \mathbb{Z}_{11}^$.
 $g = 2$, ${1, 2, 4, 8, 5, 10, 9, 7, 3, 6}$.
31.6-2  Give a modular exponentiation algorithm that examines the bits of $b$ from right to left instead of left to right.
def modular\_exponentiation(a, b, n): i, d = 0, 1 while (1 &amp;lt;&amp;lt; i) ≤ b: if (b &amp;amp; (1 &amp;lt;&amp;lt; i)) &amp;gt; 0: d = (d * a) % n a = (a * a) % n i += 1 return d  31.</description>
    </item>
    
    <item>
      <title>31.7 The RSA public-key cryptosystem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.7/</guid>
      <description>31.7-1  Consider an RSA key set with $p = 11$, $q = 29$, $n = 319$, and $e = 3$. What value of $d$ should be used in the secret key? What is the encryption of the message $M = 100$?
 $\phi(n) = (p - 1) \cdot (q - 1) = 280$.
$d = e^{-1} ~\text{mod}~ \phi(n) = 187$.
$P(M) = M^e ~\text{mod}~ n = 254$.
$S&amp;copy; = C^d ~\text{mod}~ n = 254^{187} ~\text{mod}~ n = 100$.</description>
    </item>
    
    <item>
      <title>31.8 Primality testing</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.8/</guid>
      <description>31.8-1  Prove that if an odd integer $n &amp;gt; 1$ is not a prime or a prime power, then there exists a nontrivial square root of $1$ modulo $n$.
 31.8-2 $\star$ 31.8-3  Prove that if $x$ is a nontrivial square root of $1$, modulo $n$, then $\text{gcd}(x - 1, n)$ and $\text{gcd}(x + 1, n)$ are both nontrivial divisors of $n$.
 {equation} $$\begin{array}{rlll} x^2 &amp;amp;\equiv&amp;amp; 1 &amp;amp; (\text{mod}~ n) x^2 - 1 &amp;amp;\equiv&amp;amp; 0 &amp;amp; (\text{mod}~ n) (x + 1) (x - 1) &amp;amp;\equiv&amp;amp; 0 &amp;amp; (\text{mod}~ n) \end{array} $$  {equation} $n ~|~ (x + 1)(x - 1)$, suppose $\text{gcd}(x - 1, n) = 1$, then $n ~|~ (x + 1)$, then $x \equiv -1 ~(\text{mod}~ n)$ which is trivial, it contradicts the fact that $x$ is nontrivial, therefore $\text{gcd}(x - 1, n) \ne 1$, $\text{gcd}(x + 1, n) \ne 1$.</description>
    </item>
    
    <item>
      <title>31.9 Integer factorization</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap31/31.9/</guid>
      <description>31.9-1  Referring to the execution history shown in Figure 31.7(a), when does POLLARDRHO print the factor 73 of 1387?
 $x = 84, y = 814$.
31.9-2  Suppose that we are given a function $f : \mathbb{Z}_n \rightarrow \mathbb{Z}_n$ and an initial value $x_0 \in \mathbb{Z}_n$. Define $x_i = f(x_{i - 1})$ for $i = 1, 2, \ldots$. Let $t$ and $u &amp;gt; 0$ be the smallest values such that $x_{t+i} = x_{t+u+i}$ for $i = 0, 1, \ldots$.</description>
    </item>
    
    <item>
      <title>32-1 String matching based on repetition factors</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/problems/32-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/problems/32-1/</guid>
      <description>Let $y^i$ denote the concatenation of string $y$ with itself $i$ times. For example, $(\text{ab})^3=\text{ababab}$. We say that a string $x \in \Sigma^*$ has repetition factor $r$ if $x = y ^ r$ for some string $y \in \Sigma^*$ and some $r &amp;gt; 0$. Let $\rho$ denote the largest $r$ such that $x$ has repetition factor $r$.
a. Give an efficient algorithm that takes as input a pattern $P[1 \ldots m]$ and computes the value $\rho(P_i)$ for $i = 1, 2, \ldots, m$.</description>
    </item>
    
    <item>
      <title>32.1 The naive string-matching algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.1/</guid>
      <description>32.1-1  Show the comparisons the naive string matcher makes for the pattern $P = 0001$ in the text $T = 000010001010001$.
 $\ldots{equation}
32.1-2  Suppose that all characters in the pattern $P$ are different. Show how to accelerate NAIVE-STRING-MATCHER to run in time $O(n)$ on an $n$-character text $T$.
 Suppose $T[i] \ne P[j]$, then for $k \in [1, j)$, $T[i - k] = P[j - k] \ne P[0]$, the $[i - k, i)$ are all invalid shifts which could be skipped, therefore we can compare $T[i]$ with $P[0]$ in the next iteration.</description>
    </item>
    
    <item>
      <title>32.2 The Rabin-Karp algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.2/</guid>
      <description>32.2-1  Working modulo $q = 11$, how many spurious hits does the Rabin-Karp matcher encounter in the text $T = 3141592653589793$ when looking for the pattern $P = 26$?
 $|{15, 59, 92, 26}| = 4$.
32.2-2  How would you extend the Rabin-Karp method to the problem of searching a text string for an occurrence of any one of a given set of $k$ patterns? Start by assuming that all $k$ patterns have the same length.</description>
    </item>
    
    <item>
      <title>32.3 String matching with finite automata</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.3/</guid>
      <description>32.3-1  Construct the string-matching automaton for the pattern $P = aabab$ and illustrate its operation on the text string $T = aaababaabaababaab$.
 $0 \rightarrow 1 \rightarrow 2 \rightarrow 2 \rightarrow 3 \rightarrow 4 \rightarrow 5$ $\rightarrow$ $1 \rightarrow 2 \rightarrow 3 \rightarrow 4 \rightarrow 2 \rightarrow 3 \rightarrow 4 \rightarrow 5$ $\rightarrow$ $1 \rightarrow 2 \rightarrow 3$.
32.3-2  Draw a state-transition diagram for a string-matching automaton for the pattern $ababbabbababbababbabb$ over the alphabet $\sigma = {a, b}$.</description>
    </item>
    
    <item>
      <title>32.4 The Knuth-Morris-Pratt algorithm</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap32/32.4/</guid>
      <description>32.4-1  Compute the prefix function $\pi$ for the pattern $\text{ababbabbabbababbabb}$.
 $\pi = { 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8 }$.
32.4-2  Give an upper bound on the size of $\pi^*[q]$ as a function of $q$. Give an example to show that your bound is tight.
 $\left | \pi^*[q] \right | &amp;lt; q$.</description>
    </item>
    
    <item>
      <title>33-1 Convex layers</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33-2 Maximal layers</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33-3 Ghostbusters and ghosts</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33-4 Picking up sticks</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33-5 Sparse-hulled distributions</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/problems/33-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33.1 Line-segment properties</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.1/</guid>
      <description>33.1-1  Prove that if $p_1 \times p_2$ is positive, then vector $p_1$ is clockwise from vector $p_2$ with respect to the origin $(0, 0)$ and that if this cross product is negative, then $p_1$ is counterclockwise from $p_2$.
 $\ldots{equation}
33.1-2  Professor van Pelt proposes that only the $x$-dimension needs to be tested in line 1 of ON-SEGMENT. Show why the professor is wrong.
 $(0, 0), (5, 5), (10, 0)$.</description>
    </item>
    
    <item>
      <title>33.2 Determining whether any pair of segments intersects</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.2/</guid>
      <description>33.2-1  Show that a set of $n$ line segments may contain $\Theta(n ^ 2)$ intersections.
 Star.
33.2-2  Given two segments $a$ and $b$ that are comparable at $x$, show how to determine in $O(1)$ time which of $a \succeq_x b$ or $b \succeq_x a$ holds. Assume that neither segment is vertical.
 Suppose $a = \overline{(x_1, y_1)(x_2, y_2)}$ and $b = \overline{(x_3, y_3)(x_4, y_4)}$,
{equation}\frac{x - x_1}{x_2 - x_1} = \frac{y - y_1}{y_2 - y_1} {equation} {equation}y = (x - x_1) \cdot \frac{y_2 - y_1}{x_2 - x_1} + y_1 {equation} {equation}y&amp;rsquo; = (x - x_3) \cdot \frac{y_4 - y_3}{x_4 - x_3} + y_3 {equation} Compare $y$ and $y&amp;rsquo;$.</description>
    </item>
    
    <item>
      <title>33.3 Finding the convex hull</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>33.4 Finding the closest pair of points</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap33/33.4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34-1 Independent set</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34-2 Bonnie and Clyde</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34-3 Graph coloring</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34-4 Scheduling with profits and deadlines</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/problems/34-4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34.1 Polynomial time</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34.2 Polynomial-time verification</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34.3 NP-completeness and reducibility</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34.4 NP-completeness proofs</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>34.5 NP-complete problems</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap34/34.5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-1 Bin packing</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-2 Approximating the size of a maximum clique</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-3 Weighted set-covering problem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-4 Maximum matching</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-5 Parallel machine scheduling</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-6</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35-7 An approximation algorithm for the 0-1 knapsack problem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/problems/35-7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35.1 The vertex-cover problem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35.2 The traveling-salesman problems</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35.3 The set-covering problem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35.4 Randomization and linear programming</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>35.5 The subset-sum problem</title>
      <link>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/vii-selected-topics/chap35/35.5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>4-1 Recurrence examples</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-1/</guid>
      <description>Give asymptotic upper and lower bound for $T(n)$ in each of the following recurrences. Assume that $T(n)$ is constant for $n \le 2$. Make your bounds as tight as possible, and justify your answers.
a. $T(n) = 2T(n / 2) + n^4$.
b. $T(n) = T(7n / 10) + n$.
c. $T(n) = 16T(n / 4) + n^2$.
d. $T(n) = 7T(n / 3) + n^2$.
e. $T(n) = 7T(n / 2) + n^2$.</description>
    </item>
    
    <item>
      <title>4-2 Parameter-passing costs</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-2/</guid>
      <description>Throughout this book, we assume that parameter passing during procedure calls takes constant time, even if an $N$-element array is being passed. This assumption is valid in most systems because a pointer to the array is passed, not the array itself. This problem examines the implications of three parameter-passing strategies:
 An array is passed by pointer. Time $= \Theta(1)$. An array is passed by copying. Time $= \Theta(N)$, where $N$ is the size of the array.</description>
    </item>
    
    <item>
      <title>4-3 More recurrence examples</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-3/</guid>
      <description>Give asymptotic upper and lower bounds for $T(n)$ in each of the following recurrences. Assume that $T(n)$ is constant for sufficiently small $n$. Make your bounds as tight as possible, and justify your answers.
a. $T(n) = 4T(n / 3) + n\lg n$.
b. $T(n) = 3T(n / 3) + n / \lg n$.
c. $T(n) = 4T(n / 2) + n^2\sqrt n$.
d. $T(n) = 3T(n / 3 - 2) + n / 2$.</description>
    </item>
    
    <item>
      <title>4-4 Fibonacci numbers</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-4/</guid>
      <description>This problem develops properties of the Fibonacci numbers, which are defined by recurrence $\text{(3.22)}$. We shall use the technique of generating functions to solve the Fibonacci recurrence. Define the generating function (or formal power series) $\mathcal F$ as
 $$ \begin{aligned} \mathcal F(z) &amp; = \sum_{i = 0}^{\infty} F_iz^i \\ &amp; = 0 + z + z^2 + 2z^3 + 3z^4 + 5z^5 + 8z^6 + 13z^7 + 21z^8 + \cdots, \end{aligned} $$  where $F_i$ is the $i$th Fibonacci number.</description>
    </item>
    
    <item>
      <title>4-5 Chip testing</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-5/</guid>
      <description>Professor Diogenes has $n$ supposedly identical integrated-circuit chips that in principle are capable of testing each other. The professor&amp;rsquo;s test jig accomodates two chips at a time. When the jig is loaded, each chip tests the other and reports whether it is good or bad. A good chip always reports accurately whether the other chip is good or bad, but the professor cannot trust the answer of a bad chip.</description>
    </item>
    
    <item>
      <title>4-6 Monge arrays</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/problems/4-6/</guid>
      <description>An $m \times n$ array $A$ of real numbers is a Monge array if for all $i$, $j$, $k$, and $l$ such that $1 \le i &amp;lt; k \le m$ and $1 \le j &amp;lt; l \le n$, we have
 $$ A[i, j] + A[k, l] \le A[i, l] + A[k, j] $$  In other words, whenever we pick two rows and two columns of a Monge array and consider the four elements at the intersections of the rows and columns, the sum of the upper-left and lower-right elements is less than or equal to the sum of the lower-left and upper-right elements.</description>
    </item>
    
    <item>
      <title>4.1 The maximum-subarray problem</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.1/</guid>
      <description>4.1-1  What does $\text{FIND-MAXIMUM-SUBARRAY}$ return when all elements of $A$ are negative?
 If the index of the greatest element of $A$ is $i$, it returns $(i, i, A[i])$.
4.1-2  Write pseudocode for the brute-force method of solving the maximum-subarray problem. Your procedure should run in $\Theta(n^2)$ time.
 MAX-SUBARRAY-BRUTE-FORCE(A) n = A.length max-so-far = -∞ for l = 1 to n sum = 0 for h = 1 to n sum = sum + A[h] if sum &amp;gt; max-so-far max-so-far = sum low = l high = h return (low, high)  4.</description>
    </item>
    
    <item>
      <title>4.2 Strassen&#39;s algorithm for matrix multiplication</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.2/</guid>
      <description>4.2-1  Use Strassen&amp;rsquo;s algorithm to compute the matrix product
 $$ \begin{pmatrix} 1 &amp; 2 \\ 7 &amp; 5 \end{pmatrix} \begin{pmatrix} 6 &amp; 8 \\ 4 &amp; 2 \end{pmatrix} $$  Show your work.
 The first matrices are
 $$ \begin{array}{ll} S_1 = 6 &amp; S_6 = 8 \\ S_2 = 4 &amp; S_7 = -2 \\ S_3 = 12 &amp; S_8 = 6 \\ S_4 = -2 &amp; S_9 = -6 \\ S_5 = 5 &amp; S_{10} = 14.</description>
    </item>
    
    <item>
      <title>4.3 The substitution method for solving recurrences</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.3/</guid>
      <description>4.3-1  Show that the solution of $T(n) = T(n - 1) + n$ is $O(n^2)$.
 We guess $T(n) \le cn^2$ for some constant $c &amp;gt; 0$. We have
 $$ \begin{aligned} T(n) &amp; = T(n - 1) + n \\ &amp; \le c(n - 1)^2 + n \\ &amp; = cn^2 - 2cn + c + n \\ &amp; = cn^2 + c(1 - 2n) + n. \end{aligned} $$  The last quantity is less than or equal to $cn^2$ if $c(1 - 2n) + n \le 0$ or, equivalently, $c \ge n / (2n - 1)$.</description>
    </item>
    
    <item>
      <title>4.4 The recursion-tree method for solving recurrences</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.4/</guid>
      <description>4.4-1  Use a recursion tree to determine a good asymptotic upper bound on the recurrence $T(n) = 3T(\lfloor n / 2 \rfloor) + n$. Use the substitution method to verify your answer.
  The subproblem size for a node at depth $i$ is $n / 2^i$, thus the tree has $\log_2 n + 1$ levels and $3^{\log_2 n} = n^{\log_2 3}$ leaves.
The total cost over all nodes at depth $i$, for $i = 0, 1, 2, \ldots, \log_2 n - 1$, is $3^i(n / 2^i) = (3 / 2)^i$.</description>
    </item>
    
    <item>
      <title>4.5 The master method for solving recurrences</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.5/</guid>
      <description>4.5-1  Use the master method to give tight asymptotic bounds for the following recurrences:
a. $T(n) = 2T(n / 4) + 1$.
b. $T(n) = 2T(n / 4) + \sqrt n$.
c. $T(n) = 2T(n / 4) + n$.
d. $T(n) = 2T(n / 4) + n^2$.
 a. $\Theta(n^{\log_4 2}) = \Theta(\sqrt n)$.
b. $\Theta(n^{\log_4 2}\lg n) = \Theta(\sqrt n\lg n)$.
c. $\Theta(n)$.
d. $\Theta(n^2)$.
4.5-2  Professor Caesar wishes to develop a matrix-multiplication algorithm that is asymptotically faster than Strassen&amp;rsquo;s algorithm.</description>
    </item>
    
    <item>
      <title>4.6 Proof of the master theorem</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap04/4.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap04/4.6/</guid>
      <description>4.6-1 $\star$  Give a simple and exact expression for $n_j$ in equation $\text{(4.27)}$ for the case in which $b$ is a positive integer instead of an arbitrary real number.
 $n_j = \lceil n / b^j \rceil$.
4.6.2 $\star$  Show that if $f(n) = \Theta(n^{\log_b a}\lg^k{n})$, where $k \ge 0$, then the master recurrence has solution $T(n) = \Theta(n^{\log_b a}\lg^{k + 1}n)$. For simplicity, confine your analysis to exact powers of $b$.</description>
    </item>
    
    <item>
      <title>5-1 Probabilstic counting</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/problems/5-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/problems/5-1/</guid>
      <description>With a $b$-bit counter, we can ordinarily only count up to $2^b - 1$. With R. Morris&amp;rsquo;s probabilistic counting, we can count up to a much larger value at the expense of some loss of precision.
We let a counter value of $i$ represent that a count of $n_i$ for $i = 0, 1, \ldots, 2^b - 1$, where the $n_i$ form an increasing sequence of nonnegative values. We assume that the initial value of the counter is $0$, representing a count of $n_0 = 0$.</description>
    </item>
    
    <item>
      <title>5-2 Searching an unsorted array</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/problems/5-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/problems/5-2/</guid>
      <description>The problem examines three algorithms for searching for a value $x$ in an unsorted array $A$ consisting for $n$ elements.
Consider the following randomized strategy: pick a random index $i$ into $A$. If $A[i] = x$, then we terminate; otherwise, we continue the search by picking a new random index into $A$. We continue picking random indices into $A$ until we find an index $j$ such that $A[j] = x$ or until we have checked every element of $A$.</description>
    </item>
    
    <item>
      <title>5.1 The hiring problem</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/5.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/5.1/</guid>
      <description>5.1-1  Show that the assumption that we are always able to determine which candidate is best in line 4 of procedure $\text{HIRE-ASSISTANT}$ implies that we know a total order on the ranks of the candidates.
 A total order is a partial order that is a total relation $(\forall a, b \in A:aRb \text{ or } bRa)$. A relation is a partial order if it is reflexive, antisymmetric and transitive.</description>
    </item>
    
    <item>
      <title>5.2 Indicator random variables</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/5.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/5.2/</guid>
      <description>5.2.1  In $\text{HIRE-ASSISTANT}$, assuming that the candidates are presented in a random order, what is the probability that you hire exactly one time? What is the probability you hire exactly $n$ times?
 Since $\text{HIRE-ASSISTANT}$ always hires candidate 1, it hires exactly once if and only if no candidates other than candidate 1 are hired. This event occurs when candidate 1 is the best candidate of the $n$, which occurs with probability $1 / n$.</description>
    </item>
    
    <item>
      <title>5.3 Randomized algorithms</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/5.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/5.3/</guid>
      <description>5.3.1  Professor Marceau objects to the loop invariant used in the proof of Lemma 5.5. He questions whether it is true prior to the first iteration. He reasons that we could just as easily declare that an empty subarray contains no $0$-permutations. Therefore, the probability that an empty subarray contains a $0$-permutation should be $0$, thus invalidating the loop invariant prior to the first iteration. Rewrite the procedure $\text{RANDOMIZE-IN-PLACE}$ so that its associated loop invariant applies to a nonempty subarray prior to the first iteration, and modify the proof of Lemma 5.</description>
    </item>
    
    <item>
      <title>5.4 Probabilistic analysis and further uses of indicator random variables</title>
      <link>http://walkccc.github.io/CLRS/i-foundations/chap05/5.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/i-foundations/chap05/5.4/</guid>
      <description>5.4-1  How many people must there be in a room before the probability that someone has the same birthday as you do is at least $1 / 2$? How many people must there be before the probability that at least two people have a birthday on July 4 is greater than $1 / 2$?
 The probability of a person not having the same birthday as me is $(n - 1) / n$.</description>
    </item>
    
    <item>
      <title>6-1 Building a heap using insertion</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-1/</guid>
      <description>We can build a heap by repeatedly calling $\text{MAX-HEAP-INSERT}$ to insert the elements into the heap. Consider the following variation of the $\text{BUILD-MAX-HEAP}$ procedure:
BUILD-MAX-HEAP&#39;(A) A.heap-size = 1 for i = 2 to A.length MAX-HEAP-INSERT(A, A[i])  a. Do the procedures $\text{BUILD-MAX-HEAP}$ and $\text{BUILD-MAX-HEAP}^\prime$ always create the same heap when run on the same input array? Prove that they do, or provide a counterexample.
b. Show that in the worst case, $\text{BUILD-MAX-HEAP}^\prime$ requires $\Theta(n\lg n)$ time to build a $n$-element heap.</description>
    </item>
    
    <item>
      <title>6-2 Analysis of $d$-ary heaps</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-2/</guid>
      <description>A $d$-ary heap is like a binary heap, but (with one possible exception) non-leaf nodes have $d$ children instead of $2$ children.
a. How would you represent a $d$-ary heap in an array?
b. What is the height of a $d$-ary heap of $n$ elements in terms of $n$ and $d$?
c. Give an efficient implementation of $\text{EXTRACT-MAX}$ in a $d$-ary max-heap. Analyze its running time in terms of $d$ and $n$.</description>
    </item>
    
    <item>
      <title>6-3 Young tableaus</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/problems/6-3/</guid>
      <description>An $m \times n$ Young tableau is an $m \times n$ matrix such that the entries of each row are in sorted order from left to right and the entries of each column are in sorted order from top to bottom. Some of the entries of a Young tableau may be $\infty$, which we treat as nonexistent elements. Thus, a Young tableau can be used to hold $r \le mn$ finite numbers.</description>
    </item>
    
    <item>
      <title>6.1 Heaps</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.1/</guid>
      <description>6.1-1  What are the minimum and maximum numbers of elements in a heap of height $h$?
 Since a heap is an almost-complete binary tree (complete at all levels except possibly the lowest), it has at most $2^{h + 1} - 1$ elements (if it is complete) and at least $2^h - 1 + 1 = 2^h$ elements (if the lowest level has just $1$ element and the other levels are complete).</description>
    </item>
    
    <item>
      <title>6.2 Maintaining the heap property</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.2/</guid>
      <description>6.2-1  Using figure 6.2 as a model, illustrate the operation of $\text{MAX-HEAPIFY}(A, 3)$ on the array $A = \langle 27, 17, 3, 16, 13, 10, 1, 5, 7, 12, 4, 8, 9, 0 \rangle$.
  $$ \begin{aligned} \langle 27, 17, 3, 16, 13, 10,1, 5, 7, 12, 4, 8, 9, 0 \rangle \\ \langle 27, 17, 10, 16, 13, 3, 1, 5, 7, 12, 4, 8, 9, 0 \rangle \\ \langle 27, 17, 10, 16, 13, 9, 1, 5, 7, 12, 4, 8, 3, 0 \rangle \\ \end{aligned} $$  6.</description>
    </item>
    
    <item>
      <title>6.3 Building a heap</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.3/</guid>
      <description>6.3-1  Using figure 6.3 as a model, illustrate the operation of $\text{BUILD-MAX-HEAP}$ on the array $A = \langle 5, 3, 17, 10, 84, 19, 6, 22, 9 \rangle$.
  $$ \begin{aligned} \langle 5, 3, 17, 10, 84, 19, 6, 22, 9 \rangle \\ \langle 5, 3, 17, 22, 84, 19, 6, 10, 9 \rangle \\ \langle 5, 3, 19, 22, 84, 17, 6, 10, 9 \rangle \\ \langle 5, 84, 19, 22, 3, 17, 6, 10, 9 \rangle \\ \langle 84, 5, 19, 22, 3, 17, 6, 10, 9 \rangle \\ \langle 84, 22, 19, 5, 3, 17, 6, 10, 9 \rangle \\ \langle 84, 22, 19, 10, 3, 17, 6, 5, 9 \rangle \\ \end{aligned} $$  6.</description>
    </item>
    
    <item>
      <title>6.4 The heapsort algorithm</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.4/</guid>
      <description>6.4-1  Using figure 6.4 as a model, illustrate the operation of $\text{HEAPSORT}$ on the array $A = \langle 5, 13, 2, 25, 7, 17, 20, 8, 4 \rangle$.
 6.4-2  Argue the correctness of $\text{HEAPSORT}$ using the following loop invariant:
At the start of each iteration of the for loop of lines 2-5, the subarray $A[1..i]$ is a max-heap containing the $i$ smallest elements of $A[1..n]$, and the subarray $A[i + 1.</description>
    </item>
    
    <item>
      <title>6.5 Priority queues</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap06/6.5/</guid>
      <description>6.5-1  Illustrate the operation $\text{HEAP-EXTRACT-MAX}$ on the heap $A = \langle 15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1 \rangle$.
  Original heap.
 Extract the max node $15$, then move $1$ to the top of the heap.
 Since $13 &amp;gt; 9 &amp;gt; 1$, swap $1$ and $13$.
 Since $12 &amp;gt; 5 &amp;gt; 1$, swap $1$ and $12$.
 Since $6 &amp;gt; 2 &amp;gt; 1$, swap $1$ and $6$.</description>
    </item>
    
    <item>
      <title>7-1 Hoare partition correctness</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-1/</guid>
      <description>The version of $\text{PARTITION}$ given in this chapter is not the original partitioning algorithm. Here is the original partition algorithm, which is due to C.A.R. Hoare:
HOARE-PARTITION(A, p, r) x = A[p] i = p - 1 j = r + 1 while TRUE repeat j = j - 1 until A[j] ≤ x repeat i = i + 1 until A[i] ≥ x if i &amp;lt; j exchange A[i] with A[j] else return j  a.</description>
    </item>
    
    <item>
      <title>7-2 Quicksort with equal element values</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-2/</guid>
      <description>The analysis of the expected running time of randomized quicksort in section 7.4.2 assumes that all element values are distinct. In this problem. we examine what happens when they are not.
a. Suppose that all element values are equal. What would be randomized quick-sort&amp;rsquo;s running time in this case?
b. The $\text{PARTITION}$ procedure returns an index $q$ such that each element of $A[p..q - 1]$ is less than or equal to $A[q]$ and each element of $A[q + 1.</description>
    </item>
    
    <item>
      <title>7-3 Alternative quicksort analysis</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-3/</guid>
      <description>An alternative analysis of the running time of randomized quicksort focuses on the expected running time of each individual recursive call to $\text{RANDOMIZED-QUICKSORT}$, rather than on the number of comparisons performed.
a. Argue that, given an array of size $n$, the probability that any particular element is chosen as the pivot is $1 / n$. Use this to define indicator random variables
 $$ X_i = I\{i\text{th smallest element is chosen as the pivot}\}.</description>
    </item>
    
    <item>
      <title>7-4 Stack depth for quicksort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-4/</guid>
      <description>The $\text{QUICKSORT}$ algorithm of Section 7.1 contains two recursive calls to itself. After $\text{QUICKSORT}$ calls $\text{PARTITION}$, it recursively sorts the left subarray and then it recursively sorts the right subarray. The second recursive call in $\text{QUICKSORT}$ is not really necessary; we can avoid it by using an iterative control structure. This technique, called tail recursion, is provided automatically by good compilers. Consider the following version of quicksort, which simulates tail recursion:</description>
    </item>
    
    <item>
      <title>7-5 Median-of-3 partition</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-5/</guid>
      <description>One way to improve the $\text{RANDOMIZED-QUICKSORT}$ procedure is to partition around a pivot that is chosen more carefully than by picking a random element from the subarray. One common approach is the median-of-3 method: choose the pivot as the median (middle element) of a set of 3 elements randomly selected from the subarray. (See exercise 7.4-6.) For this problem, let us assume that the elements of the input array $A[1.</description>
    </item>
    
    <item>
      <title>7-6 Fuzzy sorting of intervals</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/problems/7-6/</guid>
      <description>Consider the problem in which we do not know the numbers exactly. Instead, for each number, we know an interval on the real line to which it belongs. That is, we are given $n$ closed intervals of the form $[a_i, b_i]$, where $a_i \le b_i$. We wish to fuzzy-sort these intervals, i.e., to produce a permutation $\langle i_1, i_2, \ldots, i_n \rangle$ of the intervals such that for $j = 1, 2, \ldots, n$, there exists $c_j \in [a_{i_j}, b_{i_j}]$ satisfying $c_1 \le c_2 \le \cdots \le c_n$.</description>
    </item>
    
    <item>
      <title>7.1 Description of quicksort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.1/</guid>
      <description>7.1-1  Using figure 7.1 as a model, illustrate the operation of $\text{PARTITION}$ on the array $A = \langle 13, 19, 9, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle$.
  $$ \begin{aligned} \langle 13, 19, 9, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 13, 19, 9, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 13, 19, 9, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 19, 13, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 13, 19, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 13, 19, 12, 8, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 8, 19, 12, 13, 7, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 8, 7, 12, 13, 19, 4, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 8, 7, 4, 13, 19, 12, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 8, 7, 4, 13, 19, 12, 21, 2, 6, 11 \rangle \\ \langle 9, 5, 8, 7, 4, 2, 19, 12, 21, 13, 6, 11 \rangle \\ \langle 9, 5, 8, 7, 4, 2, 6, 12, 21, 13, 19, 11 \rangle \\ \langle 9, 5, 8, 7, 4, 2, 6, 11, 21, 13, 19, 12 \rangle \end{aligned} $$  7.</description>
    </item>
    
    <item>
      <title>7.2 Performance of quicksort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.2/</guid>
      <description>7.2-1  Use the substitution method to prove that the recurrence $T(n) = T(n - 1) + \Theta(n)$ has the solution $T(n) = \Theta(n^2)$, as claimed at the beginning of section 7.2.
 We represent $\Theta(n)$ as $c_2n$ and we guess that $T(n) \le c_1n^2$,
 $$ \begin{aligned} T(n) &amp; = T(n - 1) + c_2n \\ &amp; \le c_1(n - 1)^2 + c_2n \\ &amp; = c_1n^2 - 2c_1n + c_1 + c_2n &amp; (2c_1  c_2, n \ge c_1 / (2c_1 - c_2)) \\ &amp; \le c_1n^2.</description>
    </item>
    
    <item>
      <title>7.3 A randomized version of quicksort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.3/</guid>
      <description>7.3-1  Why do we analyze the expected running time of a randomized algorithm and not its worst-case running time?
 We may be interested in the worst-case performance, but in that case, the randomization is irrelevant: it won&amp;rsquo;t improve the worst case. What randomization can do is make the chance of encountering a worst-case scenario small.
7.3-2  When $\text{RANDOMIZED-QUICKSORT}$ runs, how many calls are made to the random number generator $\text{RANDOM}$ in the worst case?</description>
    </item>
    
    <item>
      <title>7.4 Analysis of quicksort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap07/7.4/</guid>
      <description>7.4-1  Show that in the recurrence
 $$ T(n) = \max\limits_{0 \le q \le n - 1} (T(q) + T(n - q - 1)) + \Theta(n), T(n) = \Omega(n^2). $$   We guess $T(n) \ge cn^2 - 2n$,
 $$ \begin{aligned} T(n) &amp; = \max_{0 \le q \le n - 1} (T(q) + T(n - q - 1)) + \Theta(n) \\ &amp; \ge \max_{0 \le q \le n - 1} (cq^2 - 2q + c(n - q - 1)^2 - 2n - 2q -1) + \Theta(n) \\ &amp; \ge c\max_{0 \le q \le n - 1} (q^2 + (n - q - 1)^2 - (2n + 4q + 1) / c) + \Theta(n) \\ &amp; \ge cn^2 - c(2n - 1) + \Theta(n) \\ &amp; \ge cn^2 - 2cn + 2c &amp; (c \le 1) \\ &amp; \ge cn^2 - 2n.</description>
    </item>
    
    <item>
      <title>8-1 Probabilistic lower bounds on comparison sorting</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-1/</guid>
      <description>In this problem, we prove a probabilistic $\Omega(n\lg n)$ lower bound on the running time of any deterministic or randomized comparison sort on $n$ distinct input elements. We begin by examining a deterministic comparison sort $A$ with decision tree $T_A$. We assume that every permutation of $A$&amp;rsquo;s inputs is equally likely.
a. Suppose that each leaf of $T_A$ is labeled with the probability that it is reached given a random input.</description>
    </item>
    
    <item>
      <title>8-2 Sorting in place in linear time</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-2/</guid>
      <description>Suppose that we have an array of $n$ data records to sort and that the key of each record has the value $0$ or $1$. An algorithm for sorting such a set of records might possess some subset of the following three desirable characteristics:
 The algorithm runs in $O(n)$ time. The algorithm is stable. The algorithm sorts in place, using no more than a constant amount of storage space in addition to the original array.</description>
    </item>
    
    <item>
      <title>8-3 Sorting variable-length items</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-3/</guid>
      <description>a. You are given an array of integers, where different integers may have different numbers of digits, but the total number of digits over all the integers in the array is $n$. Show how to sort the array in $O(n)$ time.
b. You are given an array of strings, where different strings may have different numbers of characters, but the total number of characters over all the strings is $n$.</description>
    </item>
    
    <item>
      <title>8-4 Water jugs</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-4/</guid>
      <description>Suppose that you are given $n$ red and $n$ blue water jugs, all of different shapes and sizes. All red jugs hold different amounts of water, as do the blue ones. Moreover, for every red jug, there is a blue jug that holds the same amount of water, and vice versa.
Your task is to find a grouping of the jugs into pairs of red and blue jugs that hold the same amount of water.</description>
    </item>
    
    <item>
      <title>8-5 Average sorting</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-5/</guid>
      <description>Suppose that, instead of sorting an array, we just require that the elements increase on average. More precisely, we call an $n$-element array $A$ k-sorted if, for all $i = 1, 2, \ldots, n - k$, the following holds:
 $$ \frac{\sum_{j = i}^{i + k - 1} A[j]}{k} \le \frac{\sum_{j = i + 1}^{i + k} A[j]}{k}. $$  a. What does it mean for an array to be $1$-sorted?</description>
    </item>
    
    <item>
      <title>8-6 Lower bound on merging sorted lists</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-6/</guid>
      <description>The problem of merging two sorted lists arises frequently. We have seen a procedure for it as the subroutine $\text{MERGE}$ in Section 2.3.1. In this problem, we will prove a lower bound of $2n - 1$ on the worst-case number of comparisons required to merge two sorted lists, each containing $n$ items.
First we will show a lower bound of $2n - o(n)$ comparisons by using a decision tree.</description>
    </item>
    
    <item>
      <title>8-7 The $0$-$1$ sorting lemma and columnsort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/problems/8-7/</guid>
      <description>A compare-exchange operation on two array elements $A[i]$ and $A[j]$, where $i &amp;lt; j$, has the form
COMPARE-EXCHANGE(A, i, j) if A[i] &amp;gt; A[j] exchange A[i] with A[j]  After the compare-exchange operation, we know that $A[i] \le A[j]$.
An oblivious compare-exchange algorithm operates solely by a sequence of prespecified compare-exchange operations. The indices of the positions compared in the sequence must be determined in advance, and although they can depend on the number of elements being sorted, they cannot depend on the values being sorted, nor can they depend on the result of any prior compare-exchange operation.</description>
    </item>
    
    <item>
      <title>8.1 Lower bounds for sorting</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.1/</guid>
      <description>8.1-1  What is the smallest possible depth of a leaf in a decision tree for a comparison sort?
 For a permutation $a_1 \le a_2 \le \ldots \le a_n$, there are $n - 1$ pairs of relative ordering, thus the smallest possible depth is $n - 1$.
8.1-2  Obtain asymptotically tight bounds on $\lg(n!)$ without using Stirling&amp;rsquo;s approximation. Instead, evaluate the summation $\sum_{k = 1}^n \lg k$ using techniques from Section A.</description>
    </item>
    
    <item>
      <title>8.2 Counting sort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.2/</guid>
      <description>8.2-1  Using Figure 8.2 as a model, illustrate the operation of $\text{COUNTING-SORT}$ on the array $A = \langle 6, 0, 2, 0, 1, 3, 4, 6, 1, 3, 2 \rangle$.
 We have that $C = \langle 2, 4, 6, 8, 9, 9, 11 \rangle$. Then, after successive iterations of the loop on lines 10-12, we have
 $$ \begin{aligned} B &amp; = \langle, , , , , 2, , , , , \rangle, \\ B &amp; = \langle, , , , , 2, , 3, , , \rangle, \\ B &amp; = \langle, , , 1, , 2, , 3, , , \rangle \end{aligned} $$  and at the end,</description>
    </item>
    
    <item>
      <title>8.3 Radix sort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.3/</guid>
      <description>8.3-1  Using Figure 8.3 as a model, illustrate the operation of $\text{RADIX-SORT}$ on the following list of English words: COW, DOG, SEA, RUG, ROW, MOB, BOX, TAB, BAR, EAR, TAR, DIG, BIG, TEA, NOW, FOX.
  $$ \begin{array}{cccc} 0 &amp; 1 &amp; 2 &amp; 3 \\ \text{COW} &amp; \text{SE$\textbf{A}$} &amp; \text{T$\textbf{A}$B} &amp; \text{$\textbf{B}$AR} \\ \text{DOG} &amp; \text{TE$\textbf{A}$} &amp; \text{B$\textbf{A}$R} &amp; \text{$\textbf{B}$IG} \\ \text{SEA} &amp; \text{MO$\textbf{B}$} &amp; \text{E$\textbf{A}$R} &amp; \text{$\textbf{B}$OX} \\ \text{RUG} &amp; \text{TA$\textbf{B}$} &amp; \text{T$\textbf{A}$R} &amp; \text{$\textbf{C}$OW} \\ \text{ROW} &amp; \text{DO$\textbf{G}$} &amp; \text{S$\textbf{E}$A} &amp; \text{$\textbf{D}$IG} \\ \text{MOB} &amp; \text{RU$\textbf{G}$} &amp; \text{T$\textbf{E}$A} &amp; \text{$\textbf{D}$OG} \\ \text{BOX} &amp; \text{DI$\textbf{G}$} &amp; \text{D$\textbf{I}$G} &amp; \text{$\textbf{E}$AR} \\ \text{TAB} &amp; \text{BI$\textbf{G}$} &amp; \text{B$\textbf{I}$G} &amp; \text{$\textbf{F}$OX} \\ \text{BAR} &amp; \text{BA$\textbf{R}$} &amp; \text{M$\textbf{O}$B} &amp; \text{$\textbf{M}$OB} \\ \text{EAR} &amp; \text{EA$\textbf{R}$} &amp; \text{D$\textbf{O}$G} &amp; \text{$\textbf{N}$OW} \\ \text{TAR} &amp; \text{TA$\textbf{R}$} &amp; \text{C$\textbf{O}$W} &amp; \text{$\textbf{R}$OW} \\ \text{DIG} &amp; \text{CO$\textbf{W}$} &amp; \text{R$\textbf{O}$W} &amp; \text{$\textbf{R}$UG} \\ \text{BIG} &amp; \text{RO$\textbf{W}$} &amp; \text{N$\textbf{O}$W} &amp; \text{$\textbf{S}$EA} \\ \text{TEA} &amp; \text{NO$\textbf{W}$} &amp; \text{B$\textbf{O}$X} &amp; \text{$\textbf{T}$AB} \\ \text{NOW} &amp; \text{BO$\textbf{X}$} &amp; \text{F$\textbf{O}$X} &amp; \text{$\textbf{T}$AR} \\ \text{FOX} &amp; \text{FO$\textbf{X}$} &amp; \text{R$\textbf{U}$G} &amp; \text{$\textbf{T}$EA} \\ \end{array} $$  8.</description>
    </item>
    
    <item>
      <title>8.4 Bucket sort</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap08/8.4/</guid>
      <description>8.4-1  Using Figure 8.4 as a model, illustrate the operation of $\text{BUCKET-SORT}$ on the array $A = \langle .79, .13, .16, .64, .39, .20, .89, .53, .71, .42 \rangle$.
  $$ \begin{array}{cl} R &amp; \\ 0 &amp; \\ 1 &amp; .13 .16 \\ 2 &amp; .20 \\ 3 &amp; .39 \\ 4 &amp; .42 \\ 5 &amp; .53 \\ 6 &amp; .64 \\ 7 &amp; \\ 8 &amp; .</description>
    </item>
    
    <item>
      <title>9-1 Largest $i$ numbers in sorted order</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-1/</guid>
      <description>Given a set of $n$ numbers, we wish to find the $i$ largest in sorted order using a comparison-based algorithm. Find the algorithm that implements each of the following methods with the best asymptotic worst-case running time, and analyze the running times of the algorithms in terms of $n$ and $i$ .
a. Sort the numbers, and list the $i$ largest.
b. Build a max-priority queue from the numbers, and call $\text{EXTRACT-MAX}$ $i$ times.</description>
    </item>
    
    <item>
      <title>9-2 Weighted median</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-2/</guid>
      <description>For $n$ distinct elements $x_1, x_2, \ldots, x_n$ with positive weights $w_1, w_2, \ldots, w_n$ such that $\sum_{i = 1}^n w_i = 1$, the weighted (lower) median is the element $x_k$ satisfying
 $$ \sum_{x_i and
 $$ \sum_{x_i  x_k} w_i \le \frac{1}{2}. $$  For example, if the elements are $0.1, 0.35, 0.05, 0.1, 0.15, 0.05, 0.2$ and each element equals its weight (that is, $w_i = x_i$ for $i = 1, 2, \ldots, 7$), then the median is $0.</description>
    </item>
    
    <item>
      <title>9-3 Small order statistics</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-3/</guid>
      <description>We showed that the worst-case number $T(n)$ of comparisons used by $\text{SELECT}$ to select the $i$th order statistic from $n$ numbers satisfies $T(n) = \Theta(n)$, but the constant hidden by the $\Theta$-notation is rather large. When $i$ is small relative to $n$, we can implement a different procedure that uses $\text{SELECT}$ as a subroutine but makes fewer comparisons in the worst case.
a. Describe an algorithm that uses $U_i(n)$ comparisons to find the $i$th smallest of $n$ elements, where</description>
    </item>
    
    <item>
      <title>9-4 Alternative analysis of randomized selection</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/problems/9-4/</guid>
      <description>In this problem, we use indicator random variables to analyze the $\text{RANDOMIZED-SELECT}$ procedure in a manner akin to our analysis of $\text{RANDOMIZED-QUICKSORT}$ in Section 7.4.2.
As in the quicksort analysis, we assume that all elements are distinct, and we rename the elements of the input array $A$ as $z_1, z_2, \ldots, z_n$, where $z_i$ is the $i$th smallest element. Thus, the call $\text{RANDOMIZED-SELECT}(A, 1, n, k)$ returns $z_k$.
For $1 \le i &amp;lt; j \le n$, let</description>
    </item>
    
    <item>
      <title>9.1 Minimum and maximum</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.1/</guid>
      <description>9.1-1  Show that the second smallest of $n$ elements can be found with $n + \lceil \lg n \rceil - 2$ comparisons in the worst case. ($\textit{Hint:}$ Also find the smallest element.)
 The smallest of $n$ numbers can be found with $n - 1$ comparisons by conducting a tournament as follows: Compare all the numbers in pairs. Only the smaller of each pair could possibly be the smallest of all $n$, so the problem has been reduced to that of finding the smallest of $\lceil n / 2 \rceil$ numbers.</description>
    </item>
    
    <item>
      <title>9.2 Selection in expected linear time</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.2/</guid>
      <description>9.2-1  Show that $\text{RANDOMIZED-SELECT}$ never makes a recursive call to a $0$-length array.
 Calling a $0$-length array would mean that the second and third arguments are equal. So, if the call is made on line 8, we would need that $p = q - 1$, which means that $q - p + 1 = 0$. However, $i$ is assumed to be a nonnegative number, and to be executing line 8, we would need that $i &amp;lt; k = q - p + 1 = 0$, a contradiction.</description>
    </item>
    
    <item>
      <title>9.3 Selection in worst-case linear time</title>
      <link>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://walkccc.github.io/CLRS/ii-sorting-and-order-statistics/chap09/9.3/</guid>
      <description>9.3-1  In the algorithm $\text{SELECT}$, the input elements are divided into groups of $5$. Will the algorithm work in linear time if they are divided into groups of $7$? Argue that $\text{SELECT}$ does not run in linear time if groups of $3$ are used.
 For groups of $7$, the algorithm still works in linear time. The number of elements greater than $x$ (and similarly, the number less than $x$) is at least</description>
    </item>
    
  </channel>
</rss>