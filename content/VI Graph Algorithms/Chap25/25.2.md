---
title: "25.2 The Floyd-Warshall algorithm"
---

## 25.2-1

> Run the Floyd-Warshall algorithm on the weighted, directed graph of Figure 25.2. Show the matrix $D^{(k)}$ that results for each iteration of the outer loop.

$k = 1$:

<div>
$$
\begin{pmatrix}
     0 & \infty & \infty & \infty &     -1 & \infty \\
     1 &      0 & \infty &      2 &      0 & \infty \\
\infty &      2 &      0 & \infty & \infty &     -8 \\
    -4 & \infty & \infty &      0 &     -5 & \infty \\
\infty &      7 & \infty & \infty &      0 & \infty \\
\infty &      5 &     10 & \infty & \infty & 0
\end{pmatrix}
$$
</div>

$k = 2$:

<div>
$$
\begin{pmatrix}
 0 & \infty & \infty & \infty & -1 & \infty \\
 1 &      0 & \infty &      2 &  0 & \infty \\
 3 &      2 &      0 &      4 &  2 & -    8 \\
-4 & \infty & \infty &      0 & -5 & \infty \\
 8 &      7 & \infty &      9 &  0 & \infty \\
 6 &      5 &     10 &      7 &  5 & 0
\end{pmatrix}
$$
</div>

$k = 3$:

<div>
$$
\begin{pmatrix}
 0 & \infty & \infty & \infty & -1 & \infty \\
 1 &      0 & \infty &      2 &  0 & \infty \\
 3 &      2 &      0 &      4 &  2 &     -8 \\
-4 & \infty & \infty &      0 & -5 & \infty \\
 8 &      7 & \infty &      9 &  0 & \infty \\
 6 &      5 &     10 &      7 &  5 & 0
\end{pmatrix}
$$
</div>

$k = 4$:

<div>
$$
\begin{pmatrix}
 0 & \infty & \infty & \infty & -1 & \infty \\
-2 &      0 & \infty &      2 & -3 & \infty \\
 0 &      2 &      0 &      4 & -1 &     -8 \\
-4 & \infty & \infty &      0 & -5 & \infty \\
 5 &      7 & \infty &      9 &  0 & \infty \\
 3 &      5 &     10 &      7 &  2 & 0
\end{pmatrix}
$$
</div>

$k = 5$:

<div>
$$
\begin{pmatrix}
 0 & 6 & \infty & 8 & -1 & \infty \\
-2 & 0 & \infty & 2 & -3 & \infty \\
 0 & 2 &      0 & 4 & -1 &     -8 \\
-4 & 2 & \infty & 0 & -5 & \infty \\
 5 & 7 & \infty & 9 &  0 & \infty \\
 3 & 5 &     10 & 7 &  2 & 0
\end{pmatrix}
$$
</div>

$k = 6$:

<div>
$$
\begin{pmatrix}
 0 &  6 & \infty &  8 & -1 & \infty \\
-2 &  0 & \infty &  2 & -3 & \infty \\
-5 & -3 &      0 & -1 & -6 &     -8 \\
-4 &  2 & \infty &  0 & -5 & \infty \\
 5 &  7 & \infty &  9 &  0 & \infty \\
 3 &  5 &     10 &  7 &  2 & 0
\end{pmatrix}
$$
</div>

## 25.2-2

> Show how to compute the transitive closure using the technique of Section 25.1.

We set $w\_{ij} = 1$ if $(i, j)$ is an edge, and $w\_{ij} = 0$ otherwise. Then we replace line 7 of $\text{EXTEND-SHORTEST-PATHS}(L, W)$ by $l^{\prime\prime}\_{ij} = l^{\prime\prime}\_{ij} \lor (l\_{ik} \land w\_{kj})$. Then run the $\text{SLOW-ALL-PAIRS-SHORTEST-PATHS}$ algorithm.

## 25.2-3

> Modify the $\text{FLOYD-WARSHALL}$ procedure to compute the $\prod^{(k)}$ matrices according to equations $\text{(25.6)}$ and $\text{(25.7)}$. Prove rigorously that for all $i \in V$, the predecessor subgraph $G\_{\pi, i}$ is a shortest-paths tree with root $i$. ($\textit{Hint:}$ To show that $G\_{\pi, i}$ is acyclic, first show that $\pi\_{ij}^{(k)} = l$ implies $d\_{ij}^{(k)} \ge d\_{il}^{(k)} + w\_{lj}$, according to the definition of $\pi\_{ij}^{(k)}$. Then, adapt the proof of Lemma 23.16.)

```
MOD-FLOYD-WARSHALL(W)
    n = W.rows
    D^0 = W
    PI^0 is a matrix with NIL in every entry
    for i = 1 to n
        for j = 1 to n
            if i ≠ j and D^0_{i, j} < ∞
                PI^0_{i, j} = i
    for k = 1 to n
        let D^k be a new n × n matrix.
        let PI^k be a new n × n matrix
        for i = 1 to n
            for j = 1 to n
                if d^{k - 1}_{ij} ≤ d^{k - 1}_{ik} + d^{k - 1}_{kj}
                    d^k_{ij} = d^{k - 1}_{ij}
                    PI^k_{ij} = PI^{k - 1}_{ij}
                else
                    d^k_{ij} = d^{k - 1}_{ik} + d^{k - 1}_{kj}
                    PI^k_{ij} = PI^{k - 1}_{kj}
```

In order to have that $\pi^{(k)}\_{ij} = l$, we need that $d^{(k)}\_{ij} \ge d^{(k)}\_{il} + w\_{lj}$. To see this fact, we will note that having $\pi^{(k)}\_{ij} = l$ means that a shortest path from $i$ to $j$ last goes through $l$. A path that last goes through $l$ corresponds to taking a chepest path from $i$ to $l$ and then following the single edge from $l$ to $j$. However, This means that $d\_{il} \le d\_{ij} - w\_{ij}$, which we can rearrange to get the desired inequality. We can just continue following this inequality
around, and if we ever get some cycle, $i\_1, i\_2, \ldots, i\_c$, then we would have that $d\_{ii\_1} \le d\_{ii\_1} + w\_{i\_1i\_2} + w\_{i\_2i\_3} + \cdots + w\_{i\_ci\_1}$. So, if we subtract the common term sfrom both sides, we get that $0 \le w\_{i\_ci\_1} + \sum\_{q = 1}^{c - 1} w\_{i\_qi\_{q + 1}}$. So, we have that we would only have a cycle in the precedessor graph if we ahvt that there is a zero weight cycle in the original graph. However, we would never have to go around the weight zero cycle since the constructed path of shortest weight favors ones with a fewer number of edges because of the way that we handle the equality case in equation $\text{(25.7)}$.
  

## 25.2-4

> As it appears above, the Floyd-Warshall algorithm requires $\Theta(n^3)$ space, since we compute $d\_{ij}^{(k)}$ for $i, j, k = 1, 2, \ldots, n$. Show that the following procedure, which simply drops all the superscripts, is correct, and thus only $\Theta(n^2)$ space is required.
>
> ```cpp
> FLOYD-WARSHALL'(W)
>     n = W.rows
>     D = W
>     for k = 1 to n
>         for i = 1 to n
>             for j = 1 to n
>                 d[i][j] = min(d[i][j], d[i][k] + d[k][j])
>     return D
> ```

With the superscripts, the computation is $d\_{ij}^{(k)} = \min(d\_{ij}^{(k - 1)}, d\_{ik}^{(k - 1)} + d\_{kj}^{(k - 1)})$. If, having dropped the superscripts, we were to compute and store $d\_{ik}$ or $d\_{kj}$ before using these values to compute $d\_{ij}$, we might be computing one of the following:

<div>
$$
\begin{aligned}
d_{ij}^{(k)} & = \min(d_{ij}^{(k - 1)}, d_{ik}^{(k)} + d_{kj}^{(k - 1)}), \\
d_{ij}^{(k)} & = \min(d_{ij}^{(k - 1)}, d_{ik}^{(k - 1)} + d_{kj}^{(k)}), \\
d_{ij}^{(k)} & = \min(d_{ij}^{(k - 1)}, d_{ik}^{(k)} + d_{kj}^{(k)}),
\end{aligned}
$$
</div>

In any of these scenarios, we're computing the weight of a shortest path from $i$ to $j$ with all intermediate vertices in $\{1, 2, \ldots, k\}$. If we use $d\_{ik}^{(k)}$, rather than $d\_{ik}^{(k - 1)}$, in the computation, then we're using a subpath from $i$ to $k$ with all intermediate vertices in $\{1, 2, \ldots, k\}$. But $k$ cannot be an _intermediate_ vertex on a shortest path from $i$ to $k$, since otherwise there would be a cycle on this shortest path. Thus, $d\_{ik}^{(k)} = d\_{ik}^{(k - 1)}$. A similar argument applies to show that $d\_{kj}^{(k)} = d\_{kj}^{(k - 1)}$. Hence, we can drop the superscripts in the computation.

## 25.2-5

> Suppose that we modify the way in which equation $\text{(25.7)}$ handles equality:
>
> <div>
> $$
 \pi_{ij}^{(k)} =
> \begin{cases}
> \pi_{ij}^{(k - 1)} & \text{ if } d_{ij}^{(k - 1)} <   d_{ik}^{(k - 1)} + d_{kj}^{(k - 1)}, \\
> \pi_{kj}^{(k - 1)} & \text{ if } d_{ij}^{(k - 1)} \ge d_{ik}^{(k - 1)} + d_{kj}^{(k - 1)}.
> \end{cases}
> $$
> </div>
>
> Is this alternative definition of the predecessor matrix $\prod$ correct?

If we change the way that we handle the equality case, we will still be generating a the correct values for the $\pi$ matrix. This is because updating the $\pi$ values to make paths that are longer but still tied for the lowest weight. Making $\pi\_{ij} = \pi\_{kj}$ means that we are making the shortest path from $i$ to $j$ passes through $k$ at some point. This has the same cost as just going from $i$ to $j$, since $d\_{ij} = d\_{ik} + d\_{kj}$.

## 25.2-6

> How can we use the output of the Floyd-Warshall algorithm to detect the presence of a negative-weight cycle?

Here are two ways to detect negative-weight cycles:

1. Check the main-diagonal entries of the result matrix for a negative value. There is a negative weight cycle if and only if $d\_{ii}^{(n)} < 0$ for some vertex $i$:

    - $d\_{ii}^{(n)}$ is a path weight from $i$ to itself; so if it is negative, there is a path from $i$ to itself (i.e., a cycle), with negative weight.
    - If there is a negative-weight cycle, consider the one with the fewest vertices.  
        - If it has just one vertex, then some $w\_{ii} < 0$, so $d\_{ii}$ starts out negative, and since $d$ values are never increased, it is also negative when the algorithm terminates.
        - If it has at least two vertices, let $k$ be the highest-numbered vertex in the cycle, and let $i$ be some other vertex in the cycle. $d\_{ik}^{(k - 1)}$ and $d\_{ki}^{(k - 1)}$ have correct shortest-path weights, because they are not based on negativeweight cycles. (Neither $d\_{ik}^{(k - 1)}$ nor $d\_{ki}^{(k - 1)}$ can include $k$ as an intermediate vertex, and $i$ and $k$ are on the negative-weight cycle with the fewest vertices.) Since $i \leadsto k \leadsto i$ is a negative-weight cycle, the sum of those two weights is negative, so $d\_{ii}^{(k)}$ will be set to a negative value. Since $d$ values are never increased, it is also negative when the algorithm terminates.

    In fact, it suffices to check whether $d\_{ii}^{(n - 1)} < 0$ for some vertex $i$. Here's why. A negative-weight cycle containing vertex $i$ either contains vertex $n$ or it does not. If it does not, then clearly $d\_{ii}^{(n - 1)} < 0$. If the negative-weight cycle contains vertex $n$, then consider $d\_{nn}^{(n - 1)}$. This value must be negative, since the cycle, starting and ending at vertex $n$, does not include vertex $n$ as an intermediate vertex. 

2. Alternatively, one could just run the normal $\text{FLOYD-WARSHALL}$ algorithm one extra iteration to see if any of the $d$ values change. If there are negative cycles, then some shortest-path cost will be cheaper. If there are no such cycles, then no $d$ values will change because the algorithm gives the correct shortest paths.

## 25.2-7

> Another way to reconstruct shortest paths in the Floyd-Warshall algorithm uses values $\phi\_{ij}^{(k)}$ for $i, j, k = 1, 2, \ldots, n$, where $\phi\_{ij}^{(k)}$ is the highest-numbered intermediate vertex of a shortest path from $i$ to $j$ in which all intermediate vertices are in the set $\{1, 2, \ldots, k \}$. Give a recursive formulation for $\phi\_{ij}^{(k)}$, modify the $\text{FLOYD-WARSHALL}$ procedure to compute the $\phi\_{ij}^{(k)}$ values, and rewrite the $\text{PRINT-ALLPAIRS-SHORTEST-PATH}$ procedure to take the matrix $\Phi = (\phi\_{ij}^{(n)})$ as an input. How is the matrix $\Phi$ like the $s$ table in the matrix-chain multiplication problem of Section 15.2?

We can recursively compute the values of $\phi\_{ij}^{(n)}$ by, letting it be $\phi\_{ij}^{(k - 1)}$ if $d(k) + d\_{ik}^{(k)} + d\_{ik}^{(k)} \ge d\_{ij}(k - 1)$, and otherwise, let it be $k$. This works correctly because it perfectly captures whether we decided to use vertex $k$ when we were repeatedly allowing ourselves use of each vertex one at a time. To modify Floyd-Warshall to compute this, we would just need to stick within the innermost for loop, something that computes $\phi(k)$ by this recursive rule, this would only be a constant amount of work in this innermost for loop, and so would not cause the asymptotic runtime to increase. It is similar to the s table in matrix-chain multiplication because it is computed by a similar recurrence.

If we already have the $n^3$ values in $\phi\_{ij}^{(k)}$ provided, then we can reconstruct the shortest path from $i$ to $j$ because we know that the largest vertex in the path from $i$ to $j$ is $\phi\_{ij}^{(n)}$, call it $a\_1$. Then, we know that the largest vertex in the path before $a\_1$ will be $\phi\_{ia\_1}^{(a\_1 - 1)}$ and the largest after $a\_1$ will be $\phi\_{a\_1j}^{(a\_1 - 1)}$. By continuing to recurse until we get that the largest element showing up at some point is $\text{NIL}$, we will be able to continue subdividing the path until it is entirely constructed.

## 25.2-8

> Give an $O(VE)$-time algorithm for computing the transitive closure of a directed
graph $G = (V, E)$.

Create an $n$ by $n$ matrix $A$ filled with $0$'s. We are done if we can determine the vertices reachable from a particular vertex in $O(E)$ time, since we can just compute this for each $v \in V$. To do this, assign each edge weight $1$. Then we have $\delta(v, u) \le |E|$ for all $u \in V$. By Problem 24-4 (a) we can compute $\delta(v, u)$ in $O(E)$ forall $u \in V$. If $\delta(v, u) < \infty$, set $A\_{ij} = 1$. Otherwise, leave it as $0$.


## 25.2-9

> Suppose that we can compute the transitive closure of a directed acyclic graph in $f(|V|, |E|)$ time, where $f$ is a monotonically increasing function of $|V|$ and $|E|$. Show that the time to compute the transitive closure $G^\prime = (V, E^\prime)$ of a general directed graph $G = (V, E)$ is then $f(|V|, |E|) + O(V + E^\prime)$.

First, compute the strongly connected components of the directed graph, and look at it's component graph. This component graph is going to be acyclic and have at most as many vertices and at most as many edges as the original graph. Since it is acyclic, we can run our transitive closure algorithm on it. Then, for every edge $(S\_1, S\_2)$ that shows up in the transitive closure of the component graph, we add an edge from each vertex in $S\_1$ to a vertex in $S\_2$. This takes time equal to $O(V + E^\prime)$. So, the total time required is $\le f(|V|, |E|) + O(V + E)$.
