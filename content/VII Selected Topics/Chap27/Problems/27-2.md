---
title: "27-2 Saving temporary space in matrix multiplication"
menuTitle: "Problem 27-2"
---

> The $\text{P-MATRIX-MULTIPLY-RECURSIVE}$ procedure has the disadvantage that it must allocate a temporary matrix $T$ of size $n \times n$, which can adversely affect the constants hidden by the $\Theta$-notation. The $\text{P-MATRIX-MULTIPLY-RECURSIVE}$ procedure does have high parallelism, however. For example, ignoring the constants in the $\Theta$-notation, the parallelism for multiplying $1000 \times 1000$ matrices comes to approximately $1000^3 / 10^2 = 10^7$, since $\lg 1000 \approx 10$. Most parallel computers have far fewer than 10 million processors.
>
> **a.** Describe a recursive multithreaded algorithm that eliminates the need for the temporary matrix $T$ at the cost of increasing the span to $\Theta(n)$. ($\textit{Hint:}$ Compute $C = C + AB$ following the general strategy of $\text{P-MATRIX-MULTIPLY-RECURSIVE}$, but initialize $C$ in parallel and insert a sync in a judiciously chosen location.)
>
> **b.** Give and solve recurrences for the work and span of your implementation.
>
> **c.** Analyze the parallelism of your implementation. Ignoring the constants in the $\Theta$-notation, estimate the parallelism on $1000 \times 1000$ matrices. Compare with the parallelism of $\text{P-MATRIX-MULTIPLY-RECURSIVE}$.

**a.** We initialize the output matrix $C$ using doubly nested **parallel for** loops and then call $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$, defined below.

```cpp
P-MATRIX-MULTIPLY-LESS-MEM(C, A, B)
    n = A.rows
    parallel for i = 1 to n
        parallel for j = 1 to n
            c[i][j] = 0
    P-MATRIX-MULTIPLY-RECURSIVE'(C, A, B)
```

```cpp
P-MATRIX-MULTIPLY-RECURSIVE'(C, A, B)
    n = A.rows
    if n == 1
        c11 = c11 + a11b11
    else partition A, B, and C into n / 2 Ã— n / 2 submatrices A11, A12, A21, A22; B11, B12, B21, B22; and C11, C12, C21, C22
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C12, A11, B11)    
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C12, A11, B12)
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C21, A21, B11)
    P-MATRIX-MULTIPLY-RECURSIVE'(C22, A21, B12)
    sync
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C11, A12, B21)    
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C12, A12, B22)
    spwan P-MATRIX-MULTIPLY-RECURSIVE'(C21, A22, B21)
    P-MATRIX-MULTIPLY-RECURSIVE'(C22, A22, B22)
    sync
```

**b.** The procedure $\text{P-MATRIX-MULTIPLY-LESS-MEM}$ performs $\Theta(n^2)$ work in the doubly nested **parallel for** loops, and then it calls the procedure $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$. The recurrence for the work $M\_1^\prime(n)$ of $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$ is $8M\_1^\prime(n / 2) + \Theta(1)$, which gives us $M\_1^\prime(n) = \Theta(n^3)$. Therefore, $T\_1(n) = \Theta(n^3)$.

The span of the doubly nested **parallel for** loops that initialize the output array $C$ is $\Theta(\lg n)$. In $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$, there are two groups of spawned recursive calls; therefore, the span $M\_\infty^\prime(n)$ of $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$ is given by the recurrence $M\_\infty^\prime(n) = 2M\_\infty^\prime(n / 2) + \Theta(1)$, which gives us $M\_\infty^\prime(n) = \Theta(n)$. Because the span $\Theta(n)$ of $\text{P-MATRIX-MULTIPLY-RECURSIVE}^\prime$ dominates, we have $T\_\infty(n) = \Theta(n)$.

**c.** The parallelism of $\text{P-MATRIX-MULTIPLY-LESS-MEM}$ is $\Theta(n^3 / n) = \Theta(n^2)$. Ignoring the constants in the $\Theta$-notation, the parallelism for multiplying $1000 \times 1000$ matrices is $1000^2 = 10^6$, which is only a factor of $10$ less than that of $\text{P-MATRIX-MULTIPLY-RECURSIVE}$. Although the parallelism of the new procedure is much less than that of $\text{P-MATRIX-MULTIPLY-RECURSIVE}$, the algorithm still scales well for a large number of processors.